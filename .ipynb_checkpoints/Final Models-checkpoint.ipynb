{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                  0\n",
       "time                  0\n",
       "timestamp             0\n",
       "date_of_week          0\n",
       "hour                  0\n",
       "quarter_of_year       0\n",
       "month                 0\n",
       "day_of_year           0\n",
       "day_of_month          0\n",
       "week_of_year          0\n",
       "is_lunch_break        0\n",
       "is_class_time         0\n",
       "is_weekday            0\n",
       "is_Thai_holiday       0\n",
       "is_exam_period        0\n",
       "academic_calendar     0\n",
       "weather_condition    14\n",
       "temperature          14\n",
       "humidity             14\n",
       "wind_speed           14\n",
       "pressure             14\n",
       "count_1204            0\n",
       "count_0412            0\n",
       "count_1211            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_for_ml_v4.csv')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weather_condition'].fillna(df['weather_condition'].mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = df = pd.read_csv('floored_class_schedule.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_lunch_break = pd.get_dummies(df['is_lunch_break'], prefix='lunchbreak', drop_first=True)\n",
    "is_class_time = pd.get_dummies(df['is_class_time'], prefix='classtime', drop_first=True)\n",
    "is_weekday = pd.get_dummies(df['is_weekday'], drop_first=True)\n",
    "is_Thai_holiday = pd.get_dummies(df['is_Thai_holiday'], prefix='holiday', drop_first=True)\n",
    "is_exam_period = pd.get_dummies(df['is_exam_period'], prefix='exam', drop_first=True)\n",
    "academic_calendar = pd.get_dummies(df['academic_calendar'], drop_first=True)\n",
    "weather_condition = pd.get_dummies(df['weather_condition'], drop_first=True)\n",
    "\n",
    "df.drop(['is_lunch_break', 'is_class_time', 'is_weekday', 'is_Thai_holiday', 'is_exam_period', 'academic_calendar', 'weather_condition'], axis=1, inplace=True)\n",
    "df = pd.concat([df, is_lunch_break, is_class_time, is_weekday, is_Thai_holiday, is_exam_period, academic_calendar, weather_condition], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>quarter_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>count_1204</th>\n",
       "      <th>count_0412</th>\n",
       "      <th>...</th>\n",
       "      <th>Partly Cloudy</th>\n",
       "      <th>Partly Cloudy / Windy</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Rain / Windy</th>\n",
       "      <th>Rain Shower</th>\n",
       "      <th>Showers in the Vicinity</th>\n",
       "      <th>T-Storm</th>\n",
       "      <th>T-Storm / Windy</th>\n",
       "      <th>Thunder</th>\n",
       "      <th>Thunder in the Vicinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 08:00</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 09:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 10:00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 11:00</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>2019-08-12 16:00</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>2019-08-12 17:00</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>2019-08-12 18:00</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>2019-08-12 19:00</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>2019-08-12 20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3136 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  date_of_week  hour  quarter_of_year  month  \\\n",
       "0     2019-01-01 07:00             3     7                1      1   \n",
       "1     2019-01-01 08:00             3     8                1      1   \n",
       "2     2019-01-01 09:00             3     9                1      1   \n",
       "3     2019-01-01 10:00             3    10                1      1   \n",
       "4     2019-01-01 11:00             3    11                1      1   \n",
       "...                ...           ...   ...              ...    ...   \n",
       "3131  2019-08-12 16:00             2    16                3      8   \n",
       "3132  2019-08-12 17:00             2    17                3      8   \n",
       "3133  2019-08-12 18:00             2    18                3      8   \n",
       "3134  2019-08-12 19:00             2    19                3      8   \n",
       "3135  2019-08-12 20:00             2    20                3      8   \n",
       "\n",
       "      day_of_year  day_of_month  week_of_year  count_1204  count_0412  ...  \\\n",
       "0               1             1             1           0           0  ...   \n",
       "1               1             1             1           0           0  ...   \n",
       "2               1             1             1           0           0  ...   \n",
       "3               1             1             1           0           0  ...   \n",
       "4               1             1             1           0           0  ...   \n",
       "...           ...           ...           ...         ...         ...  ...   \n",
       "3131          224            12            33           0           0  ...   \n",
       "3132          224            12            33           0           0  ...   \n",
       "3133          224            12            33           0           0  ...   \n",
       "3134          224            12            33           0           0  ...   \n",
       "3135          224            12            33           0           0  ...   \n",
       "\n",
       "      Partly Cloudy  Partly Cloudy / Windy  Rain  Rain / Windy  Rain Shower  \\\n",
       "0                 0                      0     0             0            0   \n",
       "1                 0                      0     0             0            0   \n",
       "2                 0                      0     0             0            0   \n",
       "3                 0                      0     0             0            0   \n",
       "4                 0                      0     0             0            0   \n",
       "...             ...                    ...   ...           ...          ...   \n",
       "3131              0                      0     0             0            0   \n",
       "3132              1                      0     0             0            0   \n",
       "3133              1                      0     0             0            0   \n",
       "3134              1                      0     0             0            0   \n",
       "3135              1                      0     0             0            0   \n",
       "\n",
       "      Showers in the Vicinity  T-Storm  T-Storm / Windy  Thunder  \\\n",
       "0                           0        0                0        0   \n",
       "1                           0        0                0        0   \n",
       "2                           0        0                0        0   \n",
       "3                           0        0                0        0   \n",
       "4                           0        0                0        0   \n",
       "...                       ...      ...              ...      ...   \n",
       "3131                        0        0                0        0   \n",
       "3132                        0        0                0        0   \n",
       "3133                        0        0                0        0   \n",
       "3134                        0        0                0        0   \n",
       "3135                        0        0                0        0   \n",
       "\n",
       "      Thunder in the Vicinity  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  \n",
       "...                       ...  \n",
       "3131                        0  \n",
       "3132                        0  \n",
       "3133                        0  \n",
       "3134                        0  \n",
       "3135                        0  \n",
       "\n",
       "[3136 rows x 43 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prophet = df.iloc[:3136]\n",
    "\n",
    "X_train = df.iloc[:3136]\n",
    "X_train_na = X_train[['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "X_train.drop(['date', 'time', 'temperature', 'humidity', 'wind_speed', 'pressure'], axis=1, inplace=True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>quarter_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>count_1204</th>\n",
       "      <th>count_0412</th>\n",
       "      <th>...</th>\n",
       "      <th>Partly Cloudy</th>\n",
       "      <th>Partly Cloudy / Windy</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Rain / Windy</th>\n",
       "      <th>Rain Shower</th>\n",
       "      <th>Showers in the Vicinity</th>\n",
       "      <th>T-Storm</th>\n",
       "      <th>T-Storm / Windy</th>\n",
       "      <th>Thunder</th>\n",
       "      <th>Thunder in the Vicinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>2019-08-13 07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3137</th>\n",
       "      <td>2019-08-13 14:00</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3138</th>\n",
       "      <td>2019-08-13 08:00</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3139</th>\n",
       "      <td>2019-08-13 09:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3140</th>\n",
       "      <td>2019-08-13 10:00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>225</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>2019-09-30 15:00</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>2019-09-30 17:00</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>2019-09-30 18:00</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>2019-09-30 19:00</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>2019-09-30 20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  date_of_week  hour  quarter_of_year  month  \\\n",
       "3136  2019-08-13 07:00             3     7                3      8   \n",
       "3137  2019-08-13 14:00             3    14                3      8   \n",
       "3138  2019-08-13 08:00             3     8                3      8   \n",
       "3139  2019-08-13 09:00             3     9                3      8   \n",
       "3140  2019-08-13 10:00             3    10                3      8   \n",
       "...                ...           ...   ...              ...    ...   \n",
       "3817  2019-09-30 15:00             2    15                3      9   \n",
       "3818  2019-09-30 17:00             2    17                3      9   \n",
       "3819  2019-09-30 18:00             2    18                3      9   \n",
       "3820  2019-09-30 19:00             2    19                3      9   \n",
       "3821  2019-09-30 20:00             2    20                3      9   \n",
       "\n",
       "      day_of_year  day_of_month  week_of_year  count_1204  count_0412  ...  \\\n",
       "3136          225            13            33           1           0  ...   \n",
       "3137          225            13            33           0           0  ...   \n",
       "3138          225            13            33           0           0  ...   \n",
       "3139          225            13            33           1           0  ...   \n",
       "3140          225            13            33           1           0  ...   \n",
       "...           ...           ...           ...         ...         ...  ...   \n",
       "3817          273            30            40           0           1  ...   \n",
       "3818          273            30            40           0           0  ...   \n",
       "3819          273            30            40           0           0  ...   \n",
       "3820          273            30            40           0           0  ...   \n",
       "3821          273            30            40           0           0  ...   \n",
       "\n",
       "      Partly Cloudy  Partly Cloudy / Windy  Rain  Rain / Windy  Rain Shower  \\\n",
       "3136              1                      0     0             0            0   \n",
       "3137              1                      0     0             0            0   \n",
       "3138              1                      0     0             0            0   \n",
       "3139              1                      0     0             0            0   \n",
       "3140              0                      0     0             0            0   \n",
       "...             ...                    ...   ...           ...          ...   \n",
       "3817              1                      0     0             0            0   \n",
       "3818              0                      0     0             0            0   \n",
       "3819              0                      0     0             0            0   \n",
       "3820              0                      0     0             0            0   \n",
       "3821              0                      0     0             0            0   \n",
       "\n",
       "      Showers in the Vicinity  T-Storm  T-Storm / Windy  Thunder  \\\n",
       "3136                        0        0                0        0   \n",
       "3137                        0        0                0        0   \n",
       "3138                        0        0                0        0   \n",
       "3139                        0        0                0        0   \n",
       "3140                        0        0                0        0   \n",
       "...                       ...      ...              ...      ...   \n",
       "3817                        0        0                0        0   \n",
       "3818                        0        0                0        0   \n",
       "3819                        0        0                0        0   \n",
       "3820                        0        0                0        0   \n",
       "3821                        0        0                0        0   \n",
       "\n",
       "      Thunder in the Vicinity  \n",
       "3136                        0  \n",
       "3137                        0  \n",
       "3138                        0  \n",
       "3139                        0  \n",
       "3140                        0  \n",
       "...                       ...  \n",
       "3817                        0  \n",
       "3818                        0  \n",
       "3819                        0  \n",
       "3820                        0  \n",
       "3821                        0  \n",
       "\n",
       "[686 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prophet = df.iloc[3136:]\n",
    "\n",
    "X_test = df.iloc[3136:]\n",
    "X_test_na = X_test[['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "X_test.drop(['date', 'time', 'temperature', 'humidity', 'wind_speed', 'pressure'], axis=1, inplace=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.946429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.674699</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.267857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.590361</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.267857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.267857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.321429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      temperature  humidity  wind_speed  pressure\n",
       "0        0.000000  0.674699    0.200000  0.946429\n",
       "1        0.000000  0.674699    0.266667  1.000000\n",
       "2        0.105263  0.626506    0.233333  1.000000\n",
       "3        0.157895  0.578313    0.200000  1.000000\n",
       "4        0.263158  0.481928    0.000000  1.000000\n",
       "...           ...       ...         ...       ...\n",
       "3131     0.578947  0.590361    0.400000  0.267857\n",
       "3132     0.526316  0.590361    0.466667  0.267857\n",
       "3133     0.473684  0.638554    0.533333  0.267857\n",
       "3134     0.421053  0.746988    0.400000  0.321429\n",
       "3135     0.421053  0.746988    0.233333  0.375000\n",
       "\n",
       "[3136 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X_train_na.fillna(X_train_na.mean(), inplace=True)\n",
    "X_test_na.fillna(X_test_na.mean(), inplace=True)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "scaler = MinMaxScaler().fit(X_train_na)\n",
    "X_train_na = pd.DataFrame(scaler.fit_transform(X_train_na), columns=X_train_na.columns)\n",
    "X_test_na = pd.DataFrame(scaler.fit_transform(X_test_na), columns=X_test_na.columns)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_train_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_train_na], axis=1)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test = pd.concat([X_test, X_test_na], axis=1)\n",
    "\n",
    "X_train_clone = X_train\n",
    "X_test_clone = X_test\n",
    "\n",
    "X_train.rename(columns = {'timestamp': 'ds', 'count_1204': 'y'}, inplace=True)\n",
    "X_test.rename(columns = {'timestamp': 'ds', 'count_1204': 'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_prophet = df.iloc[:3612]\n",
    "# train_prophet.rename(columns={'timestamp': 'ds', 'count_1204': 'y'}, inplace=True)\n",
    "# train_prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prophet = df.iloc[3612:]\n",
    "# test_prophet.rename(columns={'timestamp': 'ds', 'count_1204': 'y'}, inplace=True)\n",
    "# test_prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for_future = pd.concat([X_train, X_test])\n",
    "# for_future.drop(['date', 'time'], axis=1, inplace=True)\n",
    "for_future.reset_index(drop=True, inplace=True)\n",
    "for_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_plot = train_prophet[['date', 'count_1204']]\n",
    "train_plot['date'] = pd.to_datetime(train_plot['date'], dayfirst=True)\n",
    "train_plot = train_plot.groupby(['date']).sum()\n",
    "train_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plot = test_prophet[['date', 'count_1204']]\n",
    "test_plot['date'] = pd.to_datetime(test_plot['date'], dayfirst=True)\n",
    "test_plot = test_plot.groupby(['date']).sum()\n",
    "test_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(train_plot)\n",
    "# plt.plot(test_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "X_train['cap'] = 10\n",
    "X_train['floor'] = 0\n",
    "# m = Prophet(growth='logistic', changepoint_prior_scale=0.001)\n",
    "m = Prophet(changepoint_prior_scale=0.5)\n",
    "m.add_regressor('date_of_week')\n",
    "m.add_regressor('hour')\n",
    "m.add_regressor('quarter_of_year')\n",
    "m.add_regressor('month')\n",
    "m.add_regressor('day_of_year')\n",
    "m.add_regressor('day_of_month')\n",
    "m.add_regressor('week_of_year')\n",
    "m.add_regressor('lunchbreak_YES')\n",
    "m.add_regressor('classtime_YES')\n",
    "m.add_regressor('WEEKEND')\n",
    "m.add_regressor('holiday_NORMAL')\n",
    "m.add_regressor('exam_NORMAL')\n",
    "m.add_regressor('temperature')\n",
    "m.add_regressor('humidity')\n",
    "m.add_regressor('wind_speed')\n",
    "m.add_regressor('pressure')\n",
    "# m.add_regressor('2018/2')\n",
    "m.add_regressor('2018/SUMMER')\n",
    "m.add_regressor('2019/1')\n",
    "m.add_regressor('HOLIDAY')\n",
    "# m.add_regressor('Cloudy')\n",
    "m.add_regressor('Fair')\n",
    "m.add_regressor('Fair / Windy')\n",
    "m.add_regressor('Fog')\n",
    "m.add_regressor('Haze')\n",
    "m.add_regressor('Heavy Rain')\n",
    "m.add_regressor('Heavy Rain / Windy')\n",
    "m.add_regressor('Heavy T-Storm')\n",
    "m.add_regressor('Heavy T-Storm / Windy')\n",
    "m.add_regressor('Light Rain')\n",
    "m.add_regressor('Light Rain Shower')\n",
    "m.add_regressor('Light Rain Shower / Windy')\n",
    "m.add_regressor('Light Rain with Thunder')\n",
    "m.add_regressor('Mostly Cloudy')\n",
    "m.add_regressor('Mostly Cloudy / Windy')\n",
    "m.add_regressor('Partly Cloudy')\n",
    "m.add_regressor('Partly Cloudy / Windy')\n",
    "m.add_regressor('Rain')\n",
    "m.add_regressor('Rain / Windy')\n",
    "m.add_regressor('Rain Shower')\n",
    "m.add_regressor('Showers in the Vicinity')\n",
    "m.add_regressor('T-Storm')\n",
    "m.add_regressor('T-Storm / Windy')\n",
    "m.add_regressor('Thunder')\n",
    "m.add_regressor('Thunder in the Vicinity')\n",
    "m.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=1176, freq='H')\n",
    "future['cap'] = 10\n",
    "future['floor'] = 0\n",
    "future = future[(future['ds'].dt.hour >= 7) & (future['ds'].dt.hour < 21)]\n",
    "# future = future[future['ds'].dt.dayofweek < 5]\n",
    "future.reset_index(drop=True, inplace=True)\n",
    "future['date_of_week'] = for_future['date_of_week']\n",
    "future['hour'] = for_future['hour']\n",
    "future['quarter_of_year'] = for_future['quarter_of_year']\n",
    "future['month'] = for_future['month']\n",
    "future['day_of_year'] = for_future['day_of_year']\n",
    "future['day_of_month'] = for_future['day_of_month']\n",
    "future['week_of_year'] = for_future['week_of_year']\n",
    "future['lunchbreak_YES'] = for_future['lunchbreak_YES']\n",
    "future['classtime_YES'] = for_future['classtime_YES']\n",
    "future['WEEKEND'] = for_future['WEEKEND']\n",
    "future['holiday_NORMAL'] = for_future['holiday_NORMAL']\n",
    "future['exam_NORMAL'] = for_future['exam_NORMAL']\n",
    "future['temperature'] = for_future['temperature']\n",
    "future['humidity'] = for_future['humidity']\n",
    "future['wind_speed'] = for_future['wind_speed']\n",
    "future['pressure'] = for_future['pressure']\n",
    "# future['2018/2'] = for_future['2018/2']\n",
    "future['2018/SUMMER'] = for_future['2018/SUMMER']\n",
    "future['2019/1'] = for_future['2019/1']\n",
    "future['HOLIDAY'] = for_future['HOLIDAY']\n",
    "# future['Cloudy'] = for_future['Cloudy']\n",
    "future['Fair'] = for_future['Fair']\n",
    "future['Fair / Windy'] = for_future['Fair / Windy']\n",
    "future['Fog'] = for_future['Fog']\n",
    "future['Haze'] = for_future['Haze']\n",
    "future['Heavy Rain'] = for_future['Heavy Rain']\n",
    "future['Heavy Rain / Windy'] = for_future['Heavy Rain / Windy']\n",
    "future['Heavy T-Storm'] = for_future['Heavy T-Storm']\n",
    "future['Heavy T-Storm / Windy'] = for_future['Heavy T-Storm / Windy']\n",
    "future['Light Rain'] = for_future['Light Rain']\n",
    "future['Light Rain Shower'] = for_future['Light Rain Shower']\n",
    "future['Light Rain Shower / Windy'] = for_future['Light Rain Shower / Windy']\n",
    "future['Light Rain with Thunder'] = for_future['Light Rain with Thunder']\n",
    "future['Mostly Cloudy'] = for_future['Mostly Cloudy']\n",
    "future['Mostly Cloudy / Windy'] = for_future['Mostly Cloudy / Windy']\n",
    "future['Partly Cloudy'] = for_future['Partly Cloudy']\n",
    "future['Partly Cloudy / Windy'] = for_future['Partly Cloudy / Windy']\n",
    "future['Rain'] = for_future['Rain']\n",
    "future['Rain / Windy'] = for_future['Rain / Windy']\n",
    "future['Rain Shower'] = for_future['Rain Shower']\n",
    "future['Showers in the Vicinity'] = for_future['Showers in the Vicinity']\n",
    "future['T-Storm'] = for_future['T-Storm']\n",
    "future['T-Storm / Windy'] = for_future['T-Storm / Windy']\n",
    "future['Thunder'] = for_future['Thunder']\n",
    "future['Thunder in the Vicinity'] = for_future['Thunder in the Vicinity']\n",
    "\n",
    "forecast = m.predict(future)\n",
    "yhat_round = []\n",
    "for each in forecast['yhat_upper']:\n",
    "#     if ((each*10)%10 >= 6):\n",
    "#         each = math.ceil(each)\n",
    "#     else:\n",
    "#         each = math.floor(each)\n",
    "        \n",
    "    if(each < 0):\n",
    "        each = 0\n",
    "#     elif ((each*10)%10 >= 8):\n",
    "#         each = math.ceil(each)\n",
    "#     else:\n",
    "#         each = math.floor(each)\n",
    "\n",
    "#     each = math.ceil(each)\n",
    "    yhat_round.append(each)\n",
    "# forecast['yhat'] = yhat_round\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_result = forecast[['ds', 'yhat']]\n",
    "forecast_result.reset_index(drop=True, inplace=True)\n",
    "forecast_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(df):\n",
    "    each_date = []\n",
    "    \n",
    "    for ts in df['ds']:\n",
    "        ts = str(ts)\n",
    "        date = ts[0:10]\n",
    "        each_date.append(date)\n",
    "    \n",
    "    df['date'] = each_date\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_fit = forecast_result.iloc[:len(X_train)]\n",
    "forecast_fit = extract_date(forecast_fit)\n",
    "forecast_fit['date'] = pd.to_datetime(forecast_fit['date'], dayfirst=True)\n",
    "forecast_fit = forecast_fit.groupby(['date']).sum()\n",
    "forecast_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_test = forecast_result.iloc[len(X_train):]\n",
    "forecast_test = extract_date(forecast_test)\n",
    "forecast_test['date'] = pd.to_datetime(forecast_test['date'], dayfirst=True)\n",
    "forecast_test = forecast_test.groupby(['date']).sum()\n",
    "forecast_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def join_eva(train, forecast):\n",
    "    forecast = forecast[:len(train)]\n",
    "    \n",
    "    return forecast.set_index('ds')[['yhat', 'yhat_lower', 'yhat_upper']].join(train.set_index('ds'))\n",
    "\n",
    "def cal_metrics(df):\n",
    "    print(df)\n",
    "    r2 = r2_score(df['y'], df['yhat'])\n",
    "    rmse = np.sqrt(mean_squared_error(df['y'], df['yhat']))\n",
    "    mae = mean_absolute_error(df['y'], df['yhat'])\n",
    "    \n",
    "    return 'r2:', np.round(r2,4), 'rmse', np.round(rmse, 4), 'mae', np.round(mae, 4)\n",
    "\n",
    "def join_test(test, forecast):\n",
    "    forecast = forecast[-len(test):]\n",
    "    \n",
    "    return forecast.set_index('ds')[['yhat', 'yhat_lower', 'yhat_upper']].join(test.set_index('ds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_result = join_eva(X_train, forecast)\n",
    "print(cal_metrics(train_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_result = join_test(X_test, forecast)\n",
    "print(cal_metrics(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15))\n",
    "plt.subplot(311)\n",
    "plt.plot(train_plot, label='actual (train)', color='g')\n",
    "plt.plot(forecast_fit, label='forecast (train)', color='r')\n",
    "plt.plot(test_plot, label='actual (test)', color='#1f77b4')\n",
    "plt.plot(forecast_test, label='forecast (test)', color='#ff7f0e')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.xlabel('Month (Aggregrated Daily)', fontsize=20, labelpad=20)\n",
    "plt.ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.subplot(312)\n",
    "plt.plot(test_plot, label='actual (test)')\n",
    "plt.plot(forecast_test, label='forecast (test)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.xlabel('Month (Test Set Only)', fontsize=20, labelpad=20)\n",
    "plt.ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.subplot(313)\n",
    "for_plot = test_result[-27:]\n",
    "plt.plot(for_plot['y'], label='actual (hourly)')\n",
    "plt.plot(for_plot['yhat'], label='forecast (hourly)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.xlabel('Hour (2 Days)', fontsize=20, labelpad=20)\n",
    "plt.ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot, forecast_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_summed(y, yhat):\n",
    "#     print(df)\n",
    "    r2 = r2_score(y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    \n",
    "    return 'r2:', np.round(r2,4), 'rmse', np.round(rmse, 4), 'mae', np.round(mae, 4)\n",
    "\n",
    "print(cal_summed(test_plot, forecast_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test\n",
    "all features no round (0.2503, 0.5668, 0.3592)\n",
    "\n",
    "pure no round (0.1806, 0.5925, 0.4352)\n",
    "pure round at 5 (0.0887, 0.6249, 0.2762)\n",
    "pure round at 6 (0.0998, 0.6211, 0.2619)\n",
    "\n",
    "\n",
    "all features round at 5 (0.1665, 0.5976, 0.2714)\n",
    "all features round at 6 (0.1665, 0.5976, 0.2429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "result=[]\n",
    "size=[]\n",
    "i=0\n",
    "tscv = TimeSeriesSplit()\n",
    "for tr_index, val_index in tscv.split(X_train):\n",
    "    print(\"TRAIN:\", tr_index, \"TEST:\", val_index)\n",
    "    X_tr, X_val = X_train.iloc[tr_index], X_train.iloc[val_index]\n",
    "#     y_tr, y_val = y_train.iloc[tr_index], y_train.iloc[val_index]\n",
    "    \n",
    "    X_tr['cap'] = 4\n",
    "    X_tr['floor'] = 0\n",
    "    m = Prophet(growth='logistic', changepoint_prior_scale=0.1)\n",
    "    m = Prophet(changepoint_prior_scale=0.05)\n",
    "#     m.add_regressor('date_of_week')\n",
    "#     m.add_regressor('hour')\n",
    "#     m.add_regressor('quarter_of_year')\n",
    "#     m.add_regressor('month')\n",
    "#     m.add_regressor('day_of_year')\n",
    "#     m.add_regressor('day_of_month')\n",
    "#     m.add_regressor('week_of_year')\n",
    "#     m.add_regressor('is_lunch_break')\n",
    "#     m.add_regressor('is_class_time')\n",
    "#     m.add_regressor('temperature_normalized')\n",
    "#     m.add_regressor('humidity_normalized')\n",
    "#     m.add_regressor('wind_speed_normalized')\n",
    "#     m.add_regressor('pressure_normalized')\n",
    "#     m.add_regressor('2018/SUMMER')\n",
    "#     m.add_regressor('2019/1')\n",
    "#     m.add_regressor('HOLIDAY')\n",
    "#     m.add_regressor('Fair')\n",
    "#     m.add_regressor('Fair / Windy')\n",
    "#     m.add_regressor('Fog')\n",
    "#     m.add_regressor('Haze')\n",
    "#     m.add_regressor('Heavy Rain')\n",
    "#     m.add_regressor('Heavy Rain / Windy')\n",
    "#     m.add_regressor('Heavy T-Storm')\n",
    "#     m.add_regressor('Heavy T-Storm / Windy')\n",
    "#     m.add_regressor('Light Rain')\n",
    "#     m.add_regressor('Light Rain Shower')\n",
    "#     m.add_regressor('Light Rain Shower / Windy')\n",
    "#     m.add_regressor('Light Rain with Thunder')\n",
    "#     m.add_regressor('Mostly Cloudy')\n",
    "#     m.add_regressor('Mostly Cloudy / Windy')\n",
    "#     m.add_regressor('Partly Cloudy')\n",
    "#     m.add_regressor('Partly Cloudy / Windy')\n",
    "#     m.add_regressor('Rain')\n",
    "#     m.add_regressor('Rain / Windy')\n",
    "#     m.add_regressor('Rain Shower')\n",
    "#     m.add_regressor('Showers in the Vicinity')\n",
    "#     m.add_regressor('T-Storm')\n",
    "#     m.add_regressor('T-Storm / Windy')\n",
    "#     m.add_regressor('Thunder')\n",
    "#     m.add_regressor('Thunder in the Vicinity')\n",
    "    m.fit(X_tr)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=size[i], freq='H')\n",
    "    i += 1\n",
    "    future['cap'] = 4\n",
    "    future['floor'] = 0\n",
    "    future = future[(future['ds'].dt.hour >= 7) & (future['ds'].dt.hour < 21)]\n",
    "#     future = future[future['ds'].dt.dayofweek < 5]\n",
    "    future.reset_index(drop=True, inplace=True)\n",
    "#     future['date_of_week'] = X_val['date_of_week']\n",
    "#     future['hour'] = X_val['hour']\n",
    "#     future['quarter_of_year'] = X_val['quarter_of_year']\n",
    "#     future['month'] = X_val['month']\n",
    "#     future['day_of_year'] = X_val['day_of_year']\n",
    "#     future['day_of_month'] = X_val['day_of_month']\n",
    "#     future['week_of_year'] = X_val['week_of_year']\n",
    "#     future['is_lunch_break'] = X_val['is_lunch_break']\n",
    "#     future['is_class_time'] = X_val['is_class_time']\n",
    "#     future['temperature_normalized'] = X_val['temperature_normalized']\n",
    "#     future['humidity_normalized'] = X_val['humidity_normalized']\n",
    "#     future['wind_speed_normalized'] = X_val['wind_speed_normalized']\n",
    "#     future['pressure_normalized'] = X_val['pressure_normalized']\n",
    "#     future['2018/SUMMER'] = X_val['2018/SUMMER']\n",
    "#     future['2019/1'] = X_val['2019/1']\n",
    "#     future['HOLIDAY'] = X_val['HOLIDAY']\n",
    "#     future['Fair'] = X_val['Fair']\n",
    "#     future['Fair / Windy'] = X_val['Fair / Windy']\n",
    "#     future['Fog'] = X_val['Fog']\n",
    "#     future['Haze'] = X_val['Haze']\n",
    "#     future['Heavy Rain'] = X_val['Heavy Rain']\n",
    "#     future['Heavy Rain / Windy'] = X_val['Heavy Rain / Windy']\n",
    "#     future['Heavy T-Storm'] = X_val['Heavy T-Storm']\n",
    "#     future['Heavy T-Storm / Windy'] = X_val['Heavy T-Storm / Windy']\n",
    "#     future['Light Rain'] = X_val['Light Rain']\n",
    "#     future['Light Rain Shower'] = X_val['Light Rain Shower']\n",
    "#     future['Light Rain Shower / Windy'] = X_val['Light Rain Shower / Windy']\n",
    "#     future['Light Rain with Thunder'] = X_val['Light Rain with Thunder']\n",
    "#     future['Mostly Cloudy'] = X_val['Mostly Cloudy']\n",
    "#     future['Mostly Cloudy / Windy'] = X_val['Mostly Cloudy / Windy']\n",
    "#     future['Partly Cloudy'] = X_val['Partly Cloudy']\n",
    "#     future['Partly Cloudy / Windy'] = X_val['Partly Cloudy / Windy']\n",
    "#     future['Rain'] = X_val['Rain']\n",
    "#     future['Rain / Windy'] = X_val['Rain / Windy']\n",
    "#     future['Rain Shower'] = X_val['Rain Shower']\n",
    "#     future['Showers in the Vicinity'] = X_val['Showers in the Vicinity']\n",
    "#     future['T-Storm'] = X_val['T-Storm']\n",
    "#     future['T-Storm / Windy'] = X_val['T-Storm / Windy']\n",
    "#     future['Thunder'] = X_val['Thunder']\n",
    "#     future['Thunder in the Vicinity'] = X_val['Thunder in the Vicinity']\n",
    "\n",
    "    forecast = m.predict(future)\n",
    "    yhat_round = []\n",
    "    for each in forecast['yhat']:\n",
    "        if ((each*10)%10 >= 6):\n",
    "            each = math.ceil(each)\n",
    "        else:\n",
    "            each = math.floor(each)\n",
    "    #     each = math.ceil(each)\n",
    "        yhat_round.append(each)\n",
    "    forecast['yhat'] = yhat_round\n",
    "    forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "    \n",
    "    m.plot(forecast)\n",
    "    train_result = join_eva(X_tr, forecast)\n",
    "    result.append(cal_metrics(train_result))\n",
    "    test_result = join_test(X_val, forecast)\n",
    "    result.append(cal_metrics(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import product\n",
    "import statsmodels as sm\n",
    "import statsmodels.api as sm_api\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from pylab import rcParams\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo = X_train_clone[['ds', 'y']]\n",
    "endo['ds'] = pd.to_datetime(endo['ds'], dayfirst=True)\n",
    "endo.set_index('ds', inplace=True)\n",
    "endo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo = X_train_clone.drop(['y', 'count_0412', 'count_1211'],axis=1)\n",
    "exo['ds'] = pd.to_datetime(exo['ds'], dayfirst=True)\n",
    "exo.set_index('ds', inplace=True)\n",
    "exo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_test = X_test_clone.drop(['y', 'count_0412', 'count_1211'],axis=1)\n",
    "exo_test['ds'] = pd.to_datetime(exo_test['ds'], dayfirst=True)\n",
    "exo_test.set_index('ds', inplace=True)\n",
    "exo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plot(y, lags=None, figsize=(14,7), style='bmh'):\n",
    "#     if not isinstance(y, pd.Series):\n",
    "#         y = pd.Series(y)\n",
    "    with plt.style.context(style='bmh'):\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        layout = (2,2)\n",
    "        ts_ax = plt.subplot2grid(layout, (0,0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1,0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1,1))\n",
    "        y.plot(ax=ts_ax)\n",
    "        p_value = sm.tsa.stattools.adfuller(y)[1]\n",
    "        ts_ax.set_title('TSA-DF: p={0:5f}'.format(p_value))\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "ts_plot(endo, lags=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 18, 8\n",
    "decomposition = seasonal_decompose(endo, freq=14, model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = range(0, 2)\n",
    "d = 0\n",
    "q = range(0, 3)\n",
    "s = 14\n",
    "pdq = []\n",
    "seasonal_pdq = []\n",
    "for ar in p:\n",
    "    for ma in q:\n",
    "        param = (ar, d, ma)\n",
    "        sparam = (ar, d, ma, s)\n",
    "        pdq.append(param)\n",
    "        seasonal_pdq.append(sparam)\n",
    "\n",
    "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm_api.tsa.statespace.SARIMAX(endo, exog=exo, order=param, seasonal_order=param_seasonal, enforce_stationarity=False, enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            print('SARIMAX{}x{}14 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm_api.tsa.statespace.SARIMAX(endog=endo, exog=exo,\n",
    "                                order=(0, 0, 2),\n",
    "                                seasonal_order=(2, 0, 2, 14),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(16, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = results.get_prediction(start=pd.to_datetime('2019-02-01 07:00:00'), dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "\n",
    "ax = endo[pd.to_datetime('2019-01-07 07:00:00'):].plot(label='observed', figsize=(25, 15))\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7)\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "ax.set_xlabel('Hour', fontsize=20, labelpad=20)\n",
    "ax.set_ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_uc = results.get_forecast(steps=420, exog=exo_test)\n",
    "pred_ci = pred_uc.conf_int()\n",
    "\n",
    "plt.plot(pred_uc.predicted_mean)\n",
    "print(pred_uc.predicted_mean, pred_ci.iloc[:, 1])\n",
    "# ax = train_arima.plot(label='observed', figsize=(20, 15))\n",
    "# pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "# ax.fill_between(pred_ci.index,\n",
    "#                 pred_ci.iloc[:, 0],\n",
    "#                 pred_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "# ax.set_xlabel('Date')\n",
    "# ax.set_ylabel('Demand Hourly')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = pred_uc.predicted_mean\n",
    "yhat.reset_index(drop=True, inplace=True)\n",
    "X_test_clone['yhat'] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cal_metrics(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_sarimax = X_test_clone[['ds', 'y']]\n",
    "this = pred_uc.predicted_mean.reset_index(drop=True)\n",
    "for_sarimax['yhat'] = this\n",
    "for_sarimax = extract_date(for_sarimax)\n",
    "for_sarimax['date'] = pd.to_datetime(for_sarimax['date'], dayfirst=True)\n",
    "\n",
    "y_actual = for_sarimax[['date', 'y']]\n",
    "y_actual.set_index('date', inplace=True)\n",
    "y_actual = y_actual.groupby(['date']).sum()\n",
    "yhat = for_sarimax[['date', 'yhat']]\n",
    "yhat.set_index('date', inplace=True)\n",
    "yhat = yhat.groupby(['date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15))\n",
    "plt.plot(y_actual, label='actual (test)')\n",
    "plt.plot(yhat, label='forecast (test)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.xlabel('Month (Test Set Only)', fontsize=20, labelpad=20)\n",
    "plt.ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['count_1204']\n",
    "X = df.drop(['date', 'time', 'timestamp', 'count_1204', 'count_0412', 'count_1211'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_train_rfr = X_train[['y']]\n",
    "X_train_rfr = X_train.drop(['ds', 'y'], axis=1)\n",
    "y_test_rfr = X_test[['y']]\n",
    "X_test_rfr = X_test.drop(['ds', 'y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (3136, 45)\n",
      "Training Labels Shape: (3136, 1)\n",
      "Testing Features Shape: (686, 45)\n",
      "Testing Labels Shape: (686, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', X_train_rfr.shape)\n",
    "print('Training Labels Shape:', y_train_rfr.shape)\n",
    "print('Testing Features Shape:', X_test_rfr.shape)\n",
    "print('Testing Labels Shape:', y_test_rfr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_na = X_train[['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "X_train.drop(['temperature', 'humidity', 'wind_speed', 'pressure'], axis=1, inplace=True)\n",
    "\n",
    "X_test_na = X_test[['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "X_test.drop(['temperature', 'humidity', 'wind_speed', 'pressure'], axis=1, inplace=True)\n",
    "\n",
    "X_train_na.fillna(X_train_na.mean(), inplace=True)\n",
    "X_test_na.fillna(X_test_na.mean(), inplace=True)\n",
    "\n",
    "# scaler = StandardScaler().fit(X_train_na)\n",
    "scaler = MinMaxScaler().fit(X_train_na)\n",
    "X_train_na = pd.DataFrame(scaler.fit_transform(X_train_na), columns=X_train_na.columns)\n",
    "X_test_na = pd.DataFrame(scaler.fit_transform(X_test_na), columns=X_test_na.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_na = pd.DataFrame(scaler.fit_transform(X_train_na), columns=X_train_na.columns)\n",
    "X_test_na = pd.DataFrame(scaler.fit_transform(X_test_na), columns=X_test_na.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_train_na.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test_na.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_train_na], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_na], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=100, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=10,\n",
       "                      min_samples_split=8, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=150, n_jobs=None, oob_score=False,\n",
       "                      random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators = 150, random_state = 0,\n",
    "                                   min_samples_split=8, min_samples_leaf=10,max_depth=100)\n",
    "# model = RandomForestRegressor(n_estimators= 1000,\n",
    "#  min_samples_split= 2,\n",
    "#  min_samples_leaf= 4)\n",
    "model.fit(X_train_rfr, y_train_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.0264\n",
      "RMSE:  0.67\n",
      "MAE:  0.3043\n"
     ]
    }
   ],
   "source": [
    "y_predicted = model.predict(X_test_rfr)\n",
    "r2 = r2_score(y_test_rfr, y_predicted)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_rfr, y_predicted))\n",
    "mae = mean_absolute_error(y_test_rfr, y_predicted)\n",
    "\n",
    "print('R2: ', np.round(r2, 4))\n",
    "print('RMSE: ', np.round(rmse, 4))\n",
    "print('MAE: ', np.round(mae, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all features v3\n",
    "R2:  0.8892\n",
    "RMSE:  0.1385\n",
    "MAE:  0.0636\n",
    "\n",
    "all features v4\n",
    "\n",
    "{'n_estimators': 200,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 80,\n",
    " 'bootstrap': True}\n",
    "\n",
    "R2:  0.3049\n",
    "RMSE:  0.3727\n",
    "MAE:  0.1842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = pd.Series(model.feature_importances_, index=X_train_rfr.columns).sort_values(ascending=False)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = model.estimators_[5]\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = X.columns, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfr_model(X, y):\n",
    "# Perform Grid-Search\n",
    "    gsc = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': range(3,15),\n",
    "            'n_estimators': (10, 50, 100, 1000),},\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=2)\n",
    "    \n",
    "    grid_result = gsc.fit(X, y)\n",
    "    best_params = grid_result.best_params_\n",
    "    \n",
    "    rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"], random_state=False, verbose=False)\n",
    "# Perform K-Fold CV\n",
    "    scores = cross_val_score(rfr, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], 'min_samples_split': [2, 4, 6, 8, 10], 'min_samples_leaf': [2, 4, 6, 8, 10]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = True\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:   51.7s\n",
      "[Parallel(n_jobs=3)]: Done 156 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=3)]: Done 300 out of 300 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_state=None, verbose=0,\n",
       "                                                   warm_start=False),\n",
       "                   iid='deprecated', n_iter=100, n_jobs=3,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'min_samples_leaf': [2, 4, 6, 8, 10],\n",
       "                                        'min_samples_split': [2, 4, 6, 8, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = 3)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_rfr, y_train_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 4,\n",
       " 'min_samples_leaf': 10,\n",
       " 'max_depth': 70}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    y_predicted = model.predict(test_features)\n",
    "    r2 = r2_score(y_test_rfr, y_predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rfr, y_predicted))\n",
    "    mae = mean_absolute_error(y_test_rfr, y_predicted)\n",
    "    print('R2: ', np.round(r2, 4))\n",
    "    print('RMSE: ', np.round(rmse, 4))\n",
    "    print('MAE: ', np.round(mae, 4))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.0324\n",
      "RMSE:  0.6679\n",
      "MAE:  0.3053\n"
     ]
    }
   ],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test_rfr, y_test_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.0468\n",
      "RMSE:  0.6629\n",
      "MAE:  0.3074\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 80, random_state = 42, \n",
    "                                   min_samples_split=8, min_samples_leaf=6,max_depth= 80)\n",
    "base_model.fit(X_train_rfr, y_train_rfr)\n",
    "base_accuracy = evaluate(base_model, X_test_rfr, y_test_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-e03f61d933c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mCV_rfc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mCV_rfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
     ]
    }
   ],
   "source": [
    "CV_rfc = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 5, verbose=2, n_jobs = 3)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'max_depth': 80,\n",
    " 'min_samples_leaf': 6,\n",
    " 'min_samples_split': 8,\n",
    " 'n_estimators': 100}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
