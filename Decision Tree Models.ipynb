{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merged_no_hol = pd.read_csv('no_hol_v2_edited.csv')\n",
    "df_2018s2_old = pd.read_csv('2018_2_no_exam.csv')\n",
    "# df_2019s1 = pd.read_csv('2019_1.csv')\n",
    "# df_closed = pd.read_csv('closed_semester.csv')\n",
    "\n",
    "# frames = [df_2018s2_old, df_2019s1]\n",
    "# joined = pd.concat(frames)\n",
    "# df = joined[joined['Station_depart.'] == '12 CU Terrace']\n",
    "# df\n",
    "\n",
    "weather_2018s2 = pd.read_csv('2018s2_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon_merged = ['7/1/2019', '14/1/2019', '21/1/2019', '28/1/2019', '4/2/2019', '11/2/2019', '18/2/2019', '25/2/2019', '4/3/2019', '11/3/2019', '18/3/2019', '25/3/2019', '1/4/2019', '8/4/2019', '15/4/2019', '22/4/2019', '29/4/2019', '6/5/2019', '13/5/2019', '20/5/2019', '27/5/2019', '10/6/2019', '17/6/2019', '24/6/2019', '1/7/2019', '8/7/2019', '15/7/2019', '22/7/2019', '5/8/2019', '12/8/2019', '19/8/2019', '26/8/2019', '2/9/2019', '9/9/2019', '16/9/2019', '23/9/2019', '30/9/2019']\n",
    "tue_merged = ['1/1/2019', '8/1/2019', '15/1/2019', '22/1/2019', '29/1/2019', '5/2/2019', '12/2/2019', '26/2/2019', '5/3/2019', '12/3/2019', '19/3/2019', '26/3/2019', '2/4/2019', '9/4/2019', '16/4/2019', '23/4/2019', '30/4/2019', '7/5/2019', '14/5/2019', '21/5/2019', '28/5/2019', '4/6/2019', '11/6/2019', '18/6/2019', '25/6/2019', '2/7/2019', '9/7/2019', '23/7/2019', '30/7/2019', '6/8/2019', '13/8/2019', '20/8/2019', '27/8/2019', '3/9/2019', '10/9/2019', '17/9/2019', '24/9/2019']\n",
    "wed_merged = ['2/1/2019', '9/1/2019', '16/1/2019', '23/1/2019', '30/1/2019', '6/2/2019', '13/2/2019', '20/2/2019', '27/2/2019', '6/3/2019', '13/3/2019', '20/3/2019', '27/3/2019', '3/4/2019', '10/4/2019', '17/4/2019', '24/4/2019', '1/5/2019', '8/5/2019', '15/5/2019', '22/5/2019', '29/5/2019', '5/6/2019', '12/6/2019', '19/6/2019', '26/6/2019', '3/7/2019', '10/7/2019', '24/7/2019', '31/7/2019', '7/8/2019', '14/8/2019', '21/8/2019', '28/8/2019', '4/9/2019', '11/9/2019', '18/9/2019', '25/9/2019']\n",
    "thu_merged = ['3/1/2019', '10/1/2019', '17/1/2019', '24/1/2019', '31/1/2019', '7/2/2019', '14/2/2019', '21/2/2019', '28/2/2019', '7/3/2019', '14/3/2019', '21/3/2019', '28/3/2019', '4/4/2019', '11/4/2019', '18/4/2019', '25/4/2019', '2/5/2019', '9/5/2019', '16/5/2019', '23/5/2019', '30/5/2019', '6/6/2019', '13/6/2019', '20/6/2019', '27/6/2019', '4/7/2019', '11/7/2019', '18/7/2019', '25/7/2019', '1/8/2019', '8/8/2019', '15/8/2019', '22/8/2019', '29/8/2019', '5/9/2019', '12/9/2019', '19/9/2019', '26/9/2019']\n",
    "fri_merged = ['4/1/2019', '11/1/2019', '18/1/2019', '25/1/2019', '1/2/2019', '8/2/2019', '15/2/2019', '22/2/2019', '1/3/2019', '8/3/2019', '15/3/2019', '22/3/2019', '29/3/2019', '5/4/2019', '12/4/2019', '19/4/2019', '26/4/2019', '3/5/2019', '10/5/2019', '17/5/2019', '24/5/2019', '31/5/2019', '7/6/2019', '14/6/2019', '21/6/2019', '28/6/2019', '5/7/2019', '12/7/2019', '19/7/2019', '26/7/2019', '2/8/2019', '9/8/2019', '16/8/2019', '23/8/2019', '30/8/2019', '6/9/2019', '13/9/2019', '20/9/2019', '27/9/2019']\n",
    "sat_merged = ['5/1/2019', '22/6/2019']\n",
    "\n",
    "mon_merged = pd.to_datetime(mon_merged, dayfirst=True)\n",
    "tue_merged = pd.to_datetime(tue_merged, dayfirst=True)\n",
    "wed_merged = pd.to_datetime(wed_merged, dayfirst=True)\n",
    "thu_merged = pd.to_datetime(thu_merged, dayfirst=True)\n",
    "fri_merged = pd.to_datetime(fri_merged, dayfirst=True)\n",
    "\n",
    "# month = []\n",
    "# for slot in train['Date']:\n",
    "#     (d, m, y) = slot.split('/')\n",
    "#     m = int(m)\n",
    "#     if (m == 1):\n",
    "#         month.append('1-Jan')\n",
    "#     elif (m == 2):\n",
    "#         month.append('2-Feb')\n",
    "#     elif (m == 3):\n",
    "#         month.append('3-Mar')\n",
    "#     elif (m == 4):\n",
    "#         month.append('4-Apr')\n",
    "#     elif (m == 5):\n",
    "#         month.append('5-May')\n",
    "#     elif (m == 6):\n",
    "#         month.append('6-Jun')\n",
    "#     elif (m == 7):\n",
    "#         month.append('7-Jul')\n",
    "#     elif (m == 8):\n",
    "#         month.append('8-Aug')\n",
    "#     elif (m == 9):\n",
    "#         month.append('9-Sep')\n",
    "# train['Month'] = month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 7\n",
    "stop = 21.5\n",
    "\n",
    "def fill_missing(df, df_main, type):\n",
    "    date = list(dict.fromkeys(df_main['Date']))\n",
    "    \n",
    "    if (type == True):\n",
    "        oper_time = list(np.arange(start, stop, 0.5))\n",
    "    else:\n",
    "        oper_time = list(np.arange(start, stop))\n",
    "        \n",
    "    timestamp_all = []\n",
    "    \n",
    "    for each in date:\n",
    "        each = str(each)\n",
    "        each = each[0:11]\n",
    "        for h in oper_time:\n",
    "            (d, m, y) = each.split('/')\n",
    "            d, m, y, hh = int(d), int(m), int(y), int(h)\n",
    "            if (((h*10)%10) == 5):\n",
    "                timestamp = pd.Timestamp(year=y, month=m, day=d, hour=hh, minute=30)\n",
    "            else:\n",
    "                timestamp = pd.Timestamp(year=y, month=m, day=d, hour=hh)\n",
    "            timestamp_all.append(timestamp)\n",
    "\n",
    "    timestamp_fill = list(set(timestamp_all) - set((list(dict.fromkeys(df['Timestamp'])))))\n",
    "\n",
    "    demand_fill = []\n",
    "    demand_fill = [0] * len(timestamp_fill)\n",
    "\n",
    "    data_fill = {'Timestamp': timestamp_fill, 'Demand': demand_fill}    \n",
    "    df_od_fill = pd.DataFrame(data_fill)\n",
    "    df_od_fill = df_od_fill.sort_values('Timestamp')\n",
    "    df_od_fill = df_od_fill.reset_index(drop=True)\n",
    "    \n",
    "    df, backup = group_by_time(df)\n",
    "    \n",
    "    df = df.append(df_od_fill)\n",
    "    df = df.sort_values('Timestamp')\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def group_by_time(df):\n",
    "    df = df.groupby('Timestamp').sum()\n",
    "    backup = df\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    return df, backup\n",
    "\n",
    "def create_window(df, type):\n",
    "    converted_regist = []\n",
    "    \n",
    "    for slot in df['regist_dt_ICT']:\n",
    "        (h, m, s) = slot.split(':')\n",
    "        if (type == True):\n",
    "            if (int(m) >= 30):\n",
    "                time = int(h) + 0.5\n",
    "            else:\n",
    "                time = int(h)\n",
    "        else:\n",
    "            time = int(h)\n",
    "        converted_regist.append(time)    \n",
    "\n",
    "    df['Converted_Regist'] = converted_regist\n",
    "    \n",
    "    df = df[df['Converted_Regist'] >= start]\n",
    "    df = df[df['Converted_Regist'] < stop]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_timestamp(df, type): \n",
    "    df['DateTime'] = df[df.columns[0:2]].apply(lambda x : '/' .join(x.astype(str)),axis=1)\n",
    "    df['DateTime'] = df['DateTime'].str.replace(\":\", \"/\")\n",
    "    \n",
    "    timestamp_converted = []\n",
    "    \n",
    "    for slot in df['DateTime']:\n",
    "        (d, m, y, hh, mm, ss) = slot.split('/')\n",
    "        d, m, y, hh, mm = int(d), int(m), int(y), int(hh), int(mm)\n",
    "        if (type == True):\n",
    "            if (mm >= 30):\n",
    "                timestamp = pd.Timestamp(year=y, month=m, day=d, hour=hh, minute=30)\n",
    "            else:\n",
    "                timestamp = pd.Timestamp(year=y, month=m, day=d, hour=hh)\n",
    "        else:\n",
    "            timestamp = pd.Timestamp(year=y, month=m, day=d, hour=hh)\n",
    "        timestamp_converted.append(timestamp)\n",
    "        \n",
    "    df['Timestamp'] = timestamp_converted\n",
    "    \n",
    "    df = df.drop('DateTime', axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_dds(df, station):\n",
    "    date = []\n",
    "    \n",
    "    for each in df['Timestamp']:\n",
    "        each = str(each)\n",
    "        each = each[0:10]\n",
    "        date.append(each)\n",
    "        \n",
    "    df['Date'] = date\n",
    "    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "\n",
    "    day = []\n",
    "    \n",
    "    for slot in train['Date']:\n",
    "        if slot in mon_merged:\n",
    "            day.append('Mon')\n",
    "        if slot in tue_merged:\n",
    "            day.append('Tue')\n",
    "        if slot in wed_merged:\n",
    "            day.append('Wed')\n",
    "        if slot in thu_merged:\n",
    "            day.append('Thu')\n",
    "        if slot in fri_merged:\n",
    "            day.append('Fri')\n",
    "            \n",
    "    train['Day'] = day\n",
    "\n",
    "    destination = []\n",
    "#     station = int(station[0:2])\n",
    "    destination = [station] * len(df)\n",
    "    df['Destination'] = destination\n",
    "    \n",
    "    return df\n",
    "\n",
    "def add_demand(df):\n",
    "    demand = []\n",
    "    demand = [1] * len(df)\n",
    "    df['Demand'] = demand\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_regist(df):\n",
    "    converted_regist = []\n",
    "    \n",
    "    for each in df['Timestamp']:\n",
    "        each = str(each)\n",
    "        hour = int(each[11:13])\n",
    "        converted_regist.append(hour)    \n",
    "\n",
    "    df['Converted_Regist'] = converted_regist\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "# df.set_index('Date', inplace=True)\n",
    "# df_train = df\n",
    "# df = df.reset_index()\n",
    "# df\n",
    "\n",
    "# df_train = df_train_clone = df[:'2019-04-30']\n",
    "# df_test = df_test_clone = df['2019-05-01':'2019-05-23']\n",
    "# df_test = df_test_clone = df['2019-04-01':'2019-04-30']\n",
    "# df_train2 = df_train_clone2 = df['2019-08-13':'2019-09-20']\n",
    "# df_test2 = df_test_clone2 = df['2019-09-23':'2019-09-30']\n",
    "# df_test_clone = df_test_clone.reset_index()\n",
    "# df_train_clone2 = df_train_clone2.reset_index()\n",
    "# df_test_clone2 = df_test_clone2.reset_index()\n",
    "# df_train_clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_destination = date = list(dict.fromkeys(df['Station_dest.']))\n",
    "df_with_timestamp = create_timestamp(df, False)\n",
    "df = add_demand(df)\n",
    "template = {'Timestamp', 'Demand', 'Date', 'Day', 'Destination', 'Converted_Regist'}    \n",
    "df_joined = pd.DataFrame(template)\n",
    "frames = []\n",
    "\n",
    "for station in all_destination:\n",
    "    df_od = df[df['Station_dest.'] == station]\n",
    "    df_od = create_timestamp(df_od, False)\n",
    "    train, backup_train = group_by_time(df_od)\n",
    "#     train = train_clone = fill_missing(train, df_with_timestamp, False)\n",
    "    train = add_dds(train, station)\n",
    "    train = extract_regist(train)\n",
    "    frames.append(train)\n",
    "    \n",
    "df_joined = pd.concat(frames)\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined = df_joined.sort_values(['Timestamp', 'Destination'])\n",
    "df_joined = df_joined.reset_index(drop=True)\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_joined['Destination'] = df_joined['Destination'].astype('category')\n",
    "# df_joined['Converted_Regist'] = df_joined['Converted_Regist'].astype('category')\n",
    "df_joined = pd.get_dummies(df_joined)\n",
    "df_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df_joined.drop(['Timestamp', 'Date'], axis=1)\n",
    "df1.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_2 = df1.apply(le.fit_transform)\n",
    "X_2.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1['Demand']\n",
    "X = df1.drop('Demand', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.Series(model.feature_importances_, index=X_train.columns).sort_values()\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test)\n",
    "print('Accuracy {:.5f}'.format(model.score(X_test, y_test)))\n",
    "print(classification_report(y_predicted, y_test))\n",
    "cnf_matrix = metrics.confusion_matrix(y_test, y_predicted)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "dot_data = tree.export_graphviz(model, out_file=None, \n",
    "                                feature_names=X_train.columns,  \n",
    "                                class_names=y_train.name,  \n",
    "                                filled=True,  \n",
    "                                special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render('classification tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = range(1,23)\n",
    "\n",
    "for each in station:\n",
    "    print(model.predict([[1, each, 23]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANDOM FOREST AND SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 5 routes - RFR\n",
    "\n",
    "|Depart - Destination Station|2018/2|scale & rounding|upper|2019/1|scale & rounding|upper|Remark\n",
    "|----------------------------|------|----------------|-----|------|----------------|-----|------\n",
    "|12 CU Terrace - 04 Engineering|68.4%|0.6 and 6|N|56.1%|0.1 and 9|N|logistics 0-5/0-6|\n",
    "|04 Engineering - 12 CU Terrace|78.0%|0.8 and 3|N|57.0%|0.5 and 4|N|logistic no/0-3|\n",
    "|12 CU Terrace - 03 Sala Prakeaw|81.6%|0.3 and 7|Y|80.0%|0.1 and 9|Y|logistics 0-3 both|\n",
    "|04 Engineering - 22 Siam Square Soi 8|80.5%|0.5 and 6|Y|72.6%|0.9 and 6|N|logistics 0-3, 0-4|\n",
    "|04 Engineering - 21 Wittayakit Building|79.8%|0.6 and 4.5|Y|-|-|-|logistics 0-3|\n",
    "|02 Economics - 21 Wittayakit Building|-|-|-|71.1%|0.9 and 8|N|logistics 0-4|\n",
    "|02 Economics - 12 CU Terrace|-|-|-|68.1%|0.8 and 9|Y|logistics 0-4|\n",
    "\n",
    "Top 5 routes - SVM\n",
    "\n",
    "|Depart - Destination Station|2018/2|SARIMAX|AIC|round|2019/1|SARIMAX|AIC|round|\n",
    "|----------------------------|------|-------|---|-----|------|-------|---|-----|\n",
    "|12 CU Terrace - 04 Engineering|69.1%|(1,0,2)x(2,0,2,15)|808.3|6|55.6%|(0,0,2)x(2,0,2,15)|837.0|6|\n",
    "|04 Engineering - 12 CU Terrace|70.2%|(0,0,0)x(1,0,2,15)|562.0|5|65.9%|(0,0,0)x(2,0,2,15)|439.5|5|\n",
    "|12 CU Terrace - 03 Sala Prakeaw|79.3%|(1,0,2)x(2,0,2,15)|528.5|4|82.2%|(0,0,1)x(2,0,2,15)|252.3|6|\n",
    "|02 Economics - 22 Siam Square Soi 8|79.2%|(0,0,2)x(2,0,2,15)|532.7|4|73.3%|(0,0,0)x(1,0,2,15)|566.8|7|\n",
    "|04 Engineering - 21 Wittayakit Building|80.4%|(2,0,0)x(2,0,2,15)|466.4|4|-|-|-|-|\n",
    "|02 Economics - 21 Wittayakit Building|-|-|-|-|65.3%|(0,0,2)x(2,0,2,15)|544.2|7|\n",
    "|02 Economics - 12 CU Terrace|-|-|-|-|73.3%|(2,0,0)x(2,0,2,15)|559.1|3|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Day of week</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day of year</th>\n",
       "      <th>Day of month</th>\n",
       "      <th>Week of year</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Wind Speed</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>is_lunch_break</th>\n",
       "      <th>is_class_time</th>\n",
       "      <th>1204</th>\n",
       "      <th>412</th>\n",
       "      <th>1203</th>\n",
       "      <th>421</th>\n",
       "      <th>422</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>7:00</td>\n",
       "      <td>2019-01-07 07:00</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.90</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>8:00</td>\n",
       "      <td>2019-01-07 08:00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.93</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>9:00</td>\n",
       "      <td>2019-01-07 09:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.93</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>10:00</td>\n",
       "      <td>2019-01-07 10:00</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.79</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.96</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-07</td>\n",
       "      <td>11:00</td>\n",
       "      <td>2019-01-07 11:00</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.93</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>16:00</td>\n",
       "      <td>2019-05-03 16:00</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.67</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>17:00</td>\n",
       "      <td>2019-05-03 17:00</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.70</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>18:00</td>\n",
       "      <td>2019-05-03 18:00</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.70</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>19:00</td>\n",
       "      <td>2019-05-03 19:00</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.56</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.73</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>20:00</td>\n",
       "      <td>2019-05-03 20:00</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>13.0</td>\n",
       "      <td>29.76</td>\n",
       "      <td>NO</td>\n",
       "      <td>NO</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1050 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date   Time         Timestamp  Day of week  Hour  Quarter  Month  \\\n",
       "0     2019-01-07   7:00  2019-01-07 07:00            1     7        1      1   \n",
       "1     2019-01-07   8:00  2019-01-07 08:00            1     8        1      1   \n",
       "2     2019-01-07   9:00  2019-01-07 09:00            1     9        1      1   \n",
       "3     2019-01-07  10:00  2019-01-07 10:00            1    10        1      1   \n",
       "4     2019-01-07  11:00  2019-01-07 11:00            1    11        1      1   \n",
       "...          ...    ...               ...          ...   ...      ...    ...   \n",
       "1045  2019-05-03  16:00  2019-05-03 16:00            5    16        2      5   \n",
       "1046  2019-05-03  17:00  2019-05-03 17:00            5    17        2      5   \n",
       "1047  2019-05-03  18:00  2019-05-03 18:00            5    18        2      5   \n",
       "1048  2019-05-03  19:00  2019-05-03 19:00            5    19        2      5   \n",
       "1049  2019-05-03  20:00  2019-05-03 20:00            5    20        2      5   \n",
       "\n",
       "      Day of year  Day of month  Week of year  ...  Humidity Wind Speed  \\\n",
       "0               7             7             2  ...      0.89        3.0   \n",
       "1               7             7             2  ...      0.83        5.0   \n",
       "2               7             7             2  ...      0.83        5.0   \n",
       "3               7             7             2  ...      0.79        7.0   \n",
       "4               7             7             2  ...      0.70       12.0   \n",
       "...           ...           ...           ...  ...       ...        ...   \n",
       "1045          123             3            18  ...      0.44        7.0   \n",
       "1046          123             3            18  ...      0.47       13.0   \n",
       "1047          123             3            18  ...      0.49       10.0   \n",
       "1048          123             3            18  ...      0.56       12.0   \n",
       "1049          123             3            18  ...      0.63       13.0   \n",
       "\n",
       "      Pressure  is_lunch_break  is_class_time 1204 412  1203  421  422  \n",
       "0        29.90              NO             NO    0   0     1    0    0  \n",
       "1        29.93              NO             NO    2   0     0    1    0  \n",
       "2        29.93              NO            YES    0   1     0    0    0  \n",
       "3        29.96              NO            YES    0   0     0    0    0  \n",
       "4        29.93              NO            YES    1   0     0    0    0  \n",
       "...        ...             ...            ...  ...  ..   ...  ...  ...  \n",
       "1045     29.67              NO             NO    0   1     0    0    0  \n",
       "1046     29.70              NO             NO    0   0     0    0    0  \n",
       "1047     29.70              NO             NO    0   0     0    0    1  \n",
       "1048     29.73              NO             NO    0   0     0    0    0  \n",
       "1049     29.76              NO             NO    0   0     0    0    0  \n",
       "\n",
       "[1050 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2018s2 = pd.read_csv('2018_2_new.csv')\n",
    "df_2018s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2018s2['is_lunch_break'] = np.where((df_2018s2['is_lunch_break'] == 'NO'), 0, df_2018s2['is_lunch_break'])\n",
    "df_2018s2['is_lunch_break'] = np.where((df_2018s2['is_lunch_break'] == 'YES'), 1, df_2018s2['is_lunch_break'])\n",
    "\n",
    "df_2018s2['is_class_time'] = np.where((df_2018s2['is_class_time'] == 'NO'), 0, df_2018s2['is_class_time'])\n",
    "df_2018s2['is_class_time'] = np.where((df_2018s2['is_class_time'] == 'YES'), 1, df_2018s2['is_class_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['Day of week', 'Hour', 'is_lunch_break', 'is_class_time']\n",
    "X = df_2018s2[col] \n",
    "# df_use = df_2018s2[['Day of week', 'Hour', 'Temperature', 'Humidity', 'Wind Speed', 'Pressure', 'is_lunch_break', 'is_class_time', '1204']]\n",
    "\n",
    "y = df_2018s2[['1204']]\n",
    "# y = np.array(y)\n",
    "# X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# scaler.fit(X_test)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', X_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=8, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=1000, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfregressor = RandomForestRegressor(n_estimators=1000, random_state=42, max_depth=8) \n",
    "rfregressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2:  0.14466182444713416\n",
      "RMSE:  0.5056770344653702\n",
      "MAE:  0.3086431982891292\n",
      "MAE%:  1.2002791044577248\n"
     ]
    }
   ],
   "source": [
    "y_predicted = rfregressor.predict(X_test)\n",
    "r2 = r2_score(y_test, y_predicted)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_predicted))\n",
    "mae = mean_absolute_error(y_test, y_predicted)\n",
    "y_test = np.array(y_test).reshape(-1,)\n",
    "mae_p = mae/(np.mean(y_test))\n",
    "# smape = 100/len(y_test) * np.sum(np.abs(y_test - y_predicted) / ((np.abs(y_test) + np.abs(y_predicted))/2))\n",
    "\n",
    "print('R2: ', r2)\n",
    "print('RMSE: ', rmse)\n",
    "print('MAE: ', mae)\n",
    "print('MAE%: ', mae_p)\n",
    "# print('Accuracy: ', 100-mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "y_predicted_r = []\n",
    "for each in y_predicted:\n",
    "    if(each < 0):\n",
    "        each = 0\n",
    "    elif ((each*10)%10 >= 5):\n",
    "        each = math.ceil(each)\n",
    "    else:\n",
    "        each = math.floor(each)\n",
    "    y_predicted_r.append(each)\n",
    "y_predicted_r = np.array(y_predicted_r).reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.5056770344653702\n",
      "MAE:  0.26031746031746034\n",
      "MAE%:  1.012345679012346\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_predicted))\n",
    "mae = mean_absolute_error(y_test, y_predicted_r)\n",
    "mae_p = mae/(np.sum(y_test)/len(y_test))\n",
    "print('RMSE: ', rmse)\n",
    "print('MAE: ', mae)\n",
    "print('MAE%: ', mae_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = rfregressor.estimators_[5]\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = X.columns, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_predicted, edgecolors=(0, 0, 0))\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Actual')\n",
    "ax.set_ylabel('Predicted')\n",
    "ax.set_title(\"Ground Truth vs Predicted\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = [{'kernel': ['rbf'], 'gamma': 'C': [1, 10, 100, 1000, 10000]},\n",
    "               {'kernel': ['linear'], 'C': [1, 10, 100, 1000, 10000]},\n",
    "               {'kernel': ['sigmoid'], 'C': [1, 10, 100, 1000, 10000]},\n",
    "               {'kernel': ['poly'], 'degree':7,  'C': [1, 10, 100, 1000, 10000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = GridSearchCV(SVR(), params_grid, cv=5)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score for training data:', svm_model.best_score_,\"\\n\") \n",
    "\n",
    "# View the best parameters for the model found using grid search\n",
    "print('Best C:',svm_model.best_estimator_.C,\"\\n\") \n",
    "print('Best Kernel:',svm_model.best_estimator_.kernel,\"\\n\")\n",
    "print('Best Gamma:',svm_model.best_estimator_.gamma,\"\\n\")\n",
    "\n",
    "final_model = svm_model.best_estimator_\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "mape = 100*mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print('R2: ', r2)\n",
    "print('RMSE: ', rmse)\n",
    "print('MAPE: ', mape)\n",
    "print('Accuracy: ', 100-mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVR(kernel='rbf', C=100)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = clf.predict(X_test)\n",
    "r2 = r2_score(y_test, y_predicted)\n",
    "rmse = mean_squared_error(y_test, y_predicted)\n",
    "mape = 100*mean_absolute_error(y_test, y_predicted)\n",
    "\n",
    "print('R2: ', r2)\n",
    "print('RMSE: ', rmse)\n",
    "print('MAPE: ', mape)\n",
    "print('Accuracy: ', 100-mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(X, y, color = 'magenta')\n",
    "plt.plot(X, clf.predict(X), color = 'green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test.Hour, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test.Hour, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
