{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File data_for_ml_v5.csv does not exist: 'data_for_ml_v5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e246156c86b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_for_ml_v5.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File data_for_ml_v5.csv does not exist: 'data_for_ml_v5.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data_for_ml_v5.csv')\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date_of_week</th>\n",
       "      <th>hour</th>\n",
       "      <th>quarter_of_year</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>...</th>\n",
       "      <th>academic_calendar</th>\n",
       "      <th>weather_condition</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>pressure</th>\n",
       "      <th>count_1204</th>\n",
       "      <th>count_0412</th>\n",
       "      <th>count_1211</th>\n",
       "      <th>Students</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>07:00</td>\n",
       "      <td>1/1/2019 07:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>HOLIDAY</td>\n",
       "      <td>Fair</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>08:00</td>\n",
       "      <td>1/1/2019 08:00</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>HOLIDAY</td>\n",
       "      <td>Fair</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.73</td>\n",
       "      <td>8.0</td>\n",
       "      <td>30.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>09:00</td>\n",
       "      <td>1/1/2019 09:00</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>HOLIDAY</td>\n",
       "      <td>Fair</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.69</td>\n",
       "      <td>7.0</td>\n",
       "      <td>30.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>10:00</td>\n",
       "      <td>1/1/2019 10:00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>HOLIDAY</td>\n",
       "      <td>Fair</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2019</td>\n",
       "      <td>11:00</td>\n",
       "      <td>1/1/2019 11:00</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>HOLIDAY</td>\n",
       "      <td>Fair</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3817</th>\n",
       "      <td>30/9/2019</td>\n",
       "      <td>16:00</td>\n",
       "      <td>30/9/2019 16:00</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>2019/1</td>\n",
       "      <td>Fair</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3818</th>\n",
       "      <td>30/9/2019</td>\n",
       "      <td>17:00</td>\n",
       "      <td>30/9/2019 17:00</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>2019/1</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>30/9/2019</td>\n",
       "      <td>18:00</td>\n",
       "      <td>30/9/2019 18:00</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>2019/1</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3820</th>\n",
       "      <td>30/9/2019</td>\n",
       "      <td>19:00</td>\n",
       "      <td>30/9/2019 19:00</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>2019/1</td>\n",
       "      <td>Light Rain with Thunder</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.84</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3821</th>\n",
       "      <td>30/9/2019</td>\n",
       "      <td>20:00</td>\n",
       "      <td>30/9/2019 20:00</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>273</td>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>2019/1</td>\n",
       "      <td>Light Rain</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.74</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3822 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   time        timestamp  date_of_week  hour  quarter_of_year  \\\n",
       "0      1/1/2019  07:00   1/1/2019 07:00             3     7                1   \n",
       "1      1/1/2019  08:00   1/1/2019 08:00             3     8                1   \n",
       "2      1/1/2019  09:00   1/1/2019 09:00             3     9                1   \n",
       "3      1/1/2019  10:00   1/1/2019 10:00             3    10                1   \n",
       "4      1/1/2019  11:00   1/1/2019 11:00             3    11                1   \n",
       "...         ...    ...              ...           ...   ...              ...   \n",
       "3817  30/9/2019  16:00  30/9/2019 16:00             2    16                3   \n",
       "3818  30/9/2019  17:00  30/9/2019 17:00             2    17                3   \n",
       "3819  30/9/2019  18:00  30/9/2019 18:00             2    18                3   \n",
       "3820  30/9/2019  19:00  30/9/2019 19:00             2    19                3   \n",
       "3821  30/9/2019  20:00  30/9/2019 20:00             2    20                3   \n",
       "\n",
       "      month  day_of_year  day_of_month  week_of_year  ... academic_calendar  \\\n",
       "0         1            1             1             1  ...           HOLIDAY   \n",
       "1         1            1             1             1  ...           HOLIDAY   \n",
       "2         1            1             1             1  ...           HOLIDAY   \n",
       "3         1            1             1             1  ...           HOLIDAY   \n",
       "4         1            1             1             1  ...           HOLIDAY   \n",
       "...     ...          ...           ...           ...  ...               ...   \n",
       "3817      9          273            30            40  ...            2019/1   \n",
       "3818      9          273            30            40  ...            2019/1   \n",
       "3819      9          273            30            40  ...            2019/1   \n",
       "3820      9          273            30            40  ...            2019/1   \n",
       "3821      9          273            30            40  ...            2019/1   \n",
       "\n",
       "            weather_condition temperature humidity wind_speed pressure  \\\n",
       "0                        Fair        21.0     0.73        6.0    30.05   \n",
       "1                        Fair        21.0     0.73        8.0    30.08   \n",
       "2                        Fair        23.0     0.69        7.0    30.08   \n",
       "3                        Fair        24.0     0.65        6.0    30.08   \n",
       "4                        Fair        26.0     0.57        0.0    30.08   \n",
       "...                       ...         ...      ...        ...      ...   \n",
       "3817                     Fair        30.0     0.74        3.0    29.87   \n",
       "3818               Light Rain        32.0     0.66        7.0    29.73   \n",
       "3819               Light Rain        29.0     0.84        3.0    29.76   \n",
       "3820  Light Rain with Thunder        28.0     0.84       20.0    29.79   \n",
       "3821               Light Rain        28.0     0.74        3.0    29.81   \n",
       "\n",
       "     count_1204  count_0412  count_1211  Students   \n",
       "0             0           0           0          0  \n",
       "1             0           0           0          0  \n",
       "2             0           0           0          0  \n",
       "3             0           0           0          0  \n",
       "4             0           0           0          0  \n",
       "...         ...         ...         ...        ...  \n",
       "3817          0           0           1          0  \n",
       "3818          0           0           0          0  \n",
       "3819          0           0           0          0  \n",
       "3820          0           0           0          0  \n",
       "3821          0           0           0          0  \n",
       "\n",
       "[3822 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['weather_condition'].fillna(df['weather_condition'].mode().iloc[0], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic_calendar</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>course_id</th>\n",
       "      <th>class_start_time</th>\n",
       "      <th>class_end_time</th>\n",
       "      <th>FLOORED_class_start_time</th>\n",
       "      <th>CEILED_class_end_time</th>\n",
       "      <th>enrolled_students_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018/2 semester</td>\n",
       "      <td>5</td>\n",
       "      <td>201125</td>\n",
       "      <td>13:00</td>\n",
       "      <td>16:00</td>\n",
       "      <td>13:00</td>\n",
       "      <td>16:00</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018/2 semester</td>\n",
       "      <td>5</td>\n",
       "      <td>201127</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018/2 semester</td>\n",
       "      <td>5</td>\n",
       "      <td>201130</td>\n",
       "      <td>9:00</td>\n",
       "      <td>11:00</td>\n",
       "      <td>9:00</td>\n",
       "      <td>11:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018/2 semester</td>\n",
       "      <td>5</td>\n",
       "      <td>201130</td>\n",
       "      <td>11:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>11:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018/2 semester</td>\n",
       "      <td>5</td>\n",
       "      <td>201130</td>\n",
       "      <td>9:00</td>\n",
       "      <td>11:00</td>\n",
       "      <td>9:00</td>\n",
       "      <td>11:00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>2019/1 semester</td>\n",
       "      <td>6</td>\n",
       "      <td>5501214</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>2019/1 semester</td>\n",
       "      <td>3</td>\n",
       "      <td>5501225</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>2019/1 semester</td>\n",
       "      <td>3</td>\n",
       "      <td>5501225</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>2019/1 semester</td>\n",
       "      <td>2</td>\n",
       "      <td>5501315</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>2019/1 semester</td>\n",
       "      <td>2</td>\n",
       "      <td>5501417</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>9:00</td>\n",
       "      <td>12:00</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     academic_calendar  day_of_week  course_id class_start_time  \\\n",
       "0      2018/2 semester            5     201125            13:00   \n",
       "1      2018/2 semester            5     201127             9:00   \n",
       "2      2018/2 semester            5     201130             9:00   \n",
       "3      2018/2 semester            5     201130            11:00   \n",
       "4      2018/2 semester            5     201130             9:00   \n",
       "...                ...          ...        ...              ...   \n",
       "2703   2019/1 semester            6    5501214             9:00   \n",
       "2704   2019/1 semester            3    5501225             9:00   \n",
       "2705   2019/1 semester            3    5501225             9:00   \n",
       "2706   2019/1 semester            2    5501315             9:00   \n",
       "2707   2019/1 semester            2    5501417             9:00   \n",
       "\n",
       "     class_end_time FLOORED_class_start_time CEILED_class_end_time  \\\n",
       "0             16:00                    13:00                 16:00   \n",
       "1             12:00                     9:00                 12:00   \n",
       "2             11:00                     9:00                 11:00   \n",
       "3             12:00                    11:00                 12:00   \n",
       "4             11:00                     9:00                 11:00   \n",
       "...             ...                      ...                   ...   \n",
       "2703          12:00                     9:00                 12:00   \n",
       "2704          12:00                     9:00                 12:00   \n",
       "2705          12:00                     9:00                 12:00   \n",
       "2706          12:00                     9:00                 12:00   \n",
       "2707          12:00                     9:00                 12:00   \n",
       "\n",
       "      enrolled_students_amount  \n",
       "0                           53  \n",
       "1                           30  \n",
       "2                           57  \n",
       "3                           57  \n",
       "4                           46  \n",
       "...                        ...  \n",
       "2703                        24  \n",
       "2704                        20  \n",
       "2705                        17  \n",
       "2706                        31  \n",
       "2707                        25  \n",
       "\n",
       "[2708 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = pd.read_csv('class_schedule.csv')\n",
    "cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mon = cs[cs['day_of_week'] == 2]\n",
    "tue = cs[cs['day_of_week'] == 3]\n",
    "wed = cs[cs['day_of_week'] == 4]\n",
    "thu = cs[cs['day_of_week'] == 5]\n",
    "fri = cs[cs['day_of_week'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>enrolled_students_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORED_class_start_time</th>\n",
       "      <th>CEILED_class_end_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10:00</th>\n",
       "      <th>12:00</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13:00</th>\n",
       "      <th>15:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16:00</th>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:00</th>\n",
       "      <th>18:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8:00</th>\n",
       "      <th>10:00</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9:00</th>\n",
       "      <th>12:00</th>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               enrolled_students_amount\n",
       "                                                                    sum\n",
       "FLOORED_class_start_time CEILED_class_end_time                         \n",
       "10:00                    12:00                                       19\n",
       "13:00                    15:00                                       15\n",
       "                         16:00                                      102\n",
       "15:00                    18:00                                       15\n",
       "8:00                     10:00                                      143\n",
       "                         11:00                                        1\n",
       "9:00                     12:00                                      247"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mon2018_2 = mon[mon['academic_calendar'] == '2018/summer semester']\n",
    "mon_new = mon2018_2.groupby(['FLOORED_class_start_time','CEILED_class_end_time']).agg({'enrolled_students_amount': ['sum']})\n",
    "mon_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>enrolled_students_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORED_class_start_time</th>\n",
       "      <th>CEILED_class_end_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10:00</th>\n",
       "      <th>12:00</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13:00</th>\n",
       "      <th>15:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16:00</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:00</th>\n",
       "      <th>18:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8:00</th>\n",
       "      <th>10:00</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9:00</th>\n",
       "      <th>17:00</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               enrolled_students_amount\n",
       "                                                                    sum\n",
       "FLOORED_class_start_time CEILED_class_end_time                         \n",
       "10:00                    12:00                                       18\n",
       "13:00                    15:00                                       15\n",
       "                         16:00                                       79\n",
       "15:00                    18:00                                       15\n",
       "8:00                     10:00                                      143\n",
       "9:00                     17:00                                       10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tue2018_2 = tue[tue['academic_calendar'] == '2018/summer semester']\n",
    "tue_new = tue2018_2.groupby(['FLOORED_class_start_time','CEILED_class_end_time']).agg({'enrolled_students_amount': ['sum']})\n",
    "tue_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>enrolled_students_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORED_class_start_time</th>\n",
       "      <th>CEILED_class_end_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10:00</th>\n",
       "      <th>12:00</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13:00</th>\n",
       "      <th>15:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16:00</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:00</th>\n",
       "      <th>18:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8:00</th>\n",
       "      <th>10:00</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9:00</th>\n",
       "      <th>12:00</th>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               enrolled_students_amount\n",
       "                                                                    sum\n",
       "FLOORED_class_start_time CEILED_class_end_time                         \n",
       "10:00                    12:00                                       19\n",
       "13:00                    15:00                                       15\n",
       "                         16:00                                       95\n",
       "15:00                    18:00                                       15\n",
       "8:00                     10:00                                      143\n",
       "                         11:00                                        1\n",
       "9:00                     12:00                                      264"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wed2018_2 = wed[wed['academic_calendar'] == '2018/summer semester']\n",
    "wed_new = wed2018_2.groupby(['FLOORED_class_start_time','CEILED_class_end_time']).agg({'enrolled_students_amount': ['sum']})\n",
    "wed_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>enrolled_students_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORED_class_start_time</th>\n",
       "      <th>CEILED_class_end_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10:00</th>\n",
       "      <th>12:00</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13:00</th>\n",
       "      <th>15:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16:00</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:00</th>\n",
       "      <th>18:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8:00</th>\n",
       "      <th>10:00</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9:00</th>\n",
       "      <th>17:00</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               enrolled_students_amount\n",
       "                                                                    sum\n",
       "FLOORED_class_start_time CEILED_class_end_time                         \n",
       "10:00                    12:00                                       18\n",
       "13:00                    15:00                                       15\n",
       "                         16:00                                       84\n",
       "15:00                    18:00                                       15\n",
       "8:00                     10:00                                      143\n",
       "9:00                     17:00                                       10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thu2018_2 = thu[thu['academic_calendar'] == '2018/summer semester']\n",
    "thu_new = thu2018_2.groupby(['FLOORED_class_start_time','CEILED_class_end_time']).agg({'enrolled_students_amount': ['sum']})\n",
    "thu_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>enrolled_students_amount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORED_class_start_time</th>\n",
       "      <th>CEILED_class_end_time</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10:00</th>\n",
       "      <th>12:00</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">13:00</th>\n",
       "      <th>15:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16:00</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15:00</th>\n",
       "      <th>18:00</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8:00</th>\n",
       "      <th>10:00</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18:00</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9:00</th>\n",
       "      <th>12:00</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               enrolled_students_amount\n",
       "                                                                    sum\n",
       "FLOORED_class_start_time CEILED_class_end_time                         \n",
       "10:00                    12:00                                       18\n",
       "13:00                    15:00                                       15\n",
       "                         16:00                                       13\n",
       "15:00                    18:00                                       15\n",
       "8:00                     10:00                                      143\n",
       "                         18:00                                        2\n",
       "9:00                     12:00                                      258"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fri2018_2 = fri[fri['academic_calendar'] == '2018/summer semester']\n",
    "fri_new = fri2018_2.groupby(['FLOORED_class_start_time','CEILED_class_end_time']).agg({'enrolled_students_amount': ['sum']})\n",
    "fri_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_lunch_break = pd.get_dummies(df['is_lunch_break'], prefix='lunchbreak', drop_first=True)\n",
    "is_class_time = pd.get_dummies(df['is_class_time'], prefix='classtime', drop_first=True)\n",
    "is_weekday = pd.get_dummies(df['is_weekday'], drop_first=True)\n",
    "is_Thai_holiday = pd.get_dummies(df['is_Thai_holiday'], prefix='holiday', drop_first=True)\n",
    "is_exam_period = pd.get_dummies(df['is_exam_period'], prefix='exam', drop_first=True)\n",
    "academic_calendar = pd.get_dummies(df['academic_calendar'], drop_first=True)\n",
    "weather_condition = pd.get_dummies(df['weather_condition'], drop_first=True)\n",
    "\n",
    "df.drop(['is_lunch_break', 'is_class_time', 'is_weekday', 'is_Thai_holiday', 'is_exam_period', 'academic_calendar', 'weather_condition'], axis=1, inplace=True)\n",
    "df = pd.concat([df, is_lunch_break, is_class_time, is_weekday, is_Thai_holiday, is_exam_period, academic_calendar, weather_condition], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_prophet = df.iloc[:3136]\n",
    "\n",
    "X_train = df.iloc[:3136]\n",
    "X_train_na = X_train[['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "X_train.drop(['date', 'time', 'temperature', 'humidity', 'wind_speed', 'pressure'], axis=1, inplace=True)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_prophet = df.iloc[3136:]\n",
    "\n",
    "X_test = df.iloc[3136:]\n",
    "X_test_na = X_test[['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "X_test.drop(['date', 'time', 'temperature', 'humidity', 'wind_speed', 'pressure'], axis=1, inplace=True)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "X_train_na.fillna(X_train_na.mean(), inplace=True)\n",
    "X_test_na.fillna(X_test_na.mean(), inplace=True)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "scaler = MinMaxScaler().fit(X_train_na)\n",
    "X_train_na = pd.DataFrame(scaler.fit_transform(X_train_na), columns=X_train_na.columns)\n",
    "X_test_na = pd.DataFrame(scaler.fit_transform(X_test_na), columns=X_test_na.columns)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "X_train_na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_train_na], axis=1)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test = pd.concat([X_test, X_test_na], axis=1)\n",
    "\n",
    "X_train_clone = X_train\n",
    "X_test_clone = X_test\n",
    "\n",
    "X_train.rename(columns = {'timestamp': 'ds', 'count_1204': 'y'}, inplace=True)\n",
    "X_test.rename(columns = {'timestamp': 'ds', 'count_1204': 'y'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_prophet = df.iloc[:3612]\n",
    "# train_prophet.rename(columns={'timestamp': 'ds', 'count_1204': 'y'}, inplace=True)\n",
    "# train_prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_prophet = df.iloc[3612:]\n",
    "# test_prophet.rename(columns={'timestamp': 'ds', 'count_1204': 'y'}, inplace=True)\n",
    "# test_prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for_future = pd.concat([X_train, X_test])\n",
    "# for_future.drop(['date', 'time'], axis=1, inplace=True)\n",
    "for_future.reset_index(drop=True, inplace=True)\n",
    "for_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_plot = train_prophet[['date', 'count_1204']]\n",
    "train_plot['date'] = pd.to_datetime(train_plot['date'], dayfirst=True)\n",
    "train_plot = train_plot.groupby(['date']).sum()\n",
    "train_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_plot = test_prophet[['date', 'count_1204']]\n",
    "test_plot['date'] = pd.to_datetime(test_plot['date'], dayfirst=True)\n",
    "test_plot = test_plot.groupby(['date']).sum()\n",
    "test_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(train_plot)\n",
    "# plt.plot(test_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "X_train['cap'] = 10\n",
    "X_train['floor'] = 0\n",
    "# m = Prophet(growth='logistic', changepoint_prior_scale=0.001)\n",
    "m = Prophet(changepoint_prior_scale=0.5)\n",
    "m.add_regressor('date_of_week')\n",
    "m.add_regressor('hour')\n",
    "m.add_regressor('quarter_of_year')\n",
    "m.add_regressor('month')\n",
    "m.add_regressor('day_of_year')\n",
    "m.add_regressor('day_of_month')\n",
    "m.add_regressor('week_of_year')\n",
    "m.add_regressor('lunchbreak_YES')\n",
    "m.add_regressor('classtime_YES')\n",
    "m.add_regressor('WEEKEND')\n",
    "m.add_regressor('holiday_NORMAL')\n",
    "m.add_regressor('exam_NORMAL')\n",
    "m.add_regressor('temperature')\n",
    "m.add_regressor('humidity')\n",
    "m.add_regressor('wind_speed')\n",
    "m.add_regressor('pressure')\n",
    "# m.add_regressor('2018/2')\n",
    "m.add_regressor('2018/SUMMER')\n",
    "m.add_regressor('2019/1')\n",
    "m.add_regressor('HOLIDAY')\n",
    "# m.add_regressor('Cloudy')\n",
    "m.add_regressor('Fair')\n",
    "m.add_regressor('Fair / Windy')\n",
    "m.add_regressor('Fog')\n",
    "m.add_regressor('Haze')\n",
    "m.add_regressor('Heavy Rain')\n",
    "m.add_regressor('Heavy Rain / Windy')\n",
    "m.add_regressor('Heavy T-Storm')\n",
    "m.add_regressor('Heavy T-Storm / Windy')\n",
    "m.add_regressor('Light Rain')\n",
    "m.add_regressor('Light Rain Shower')\n",
    "m.add_regressor('Light Rain Shower / Windy')\n",
    "m.add_regressor('Light Rain with Thunder')\n",
    "m.add_regressor('Mostly Cloudy')\n",
    "m.add_regressor('Mostly Cloudy / Windy')\n",
    "m.add_regressor('Partly Cloudy')\n",
    "m.add_regressor('Partly Cloudy / Windy')\n",
    "m.add_regressor('Rain')\n",
    "m.add_regressor('Rain / Windy')\n",
    "m.add_regressor('Rain Shower')\n",
    "m.add_regressor('Showers in the Vicinity')\n",
    "m.add_regressor('T-Storm')\n",
    "m.add_regressor('T-Storm / Windy')\n",
    "m.add_regressor('Thunder')\n",
    "m.add_regressor('Thunder in the Vicinity')\n",
    "m.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=1176, freq='H')\n",
    "future['cap'] = 10\n",
    "future['floor'] = 0\n",
    "future = future[(future['ds'].dt.hour >= 7) & (future['ds'].dt.hour < 21)]\n",
    "# future = future[future['ds'].dt.dayofweek < 5]\n",
    "future.reset_index(drop=True, inplace=True)\n",
    "future['date_of_week'] = for_future['date_of_week']\n",
    "future['hour'] = for_future['hour']\n",
    "future['quarter_of_year'] = for_future['quarter_of_year']\n",
    "future['month'] = for_future['month']\n",
    "future['day_of_year'] = for_future['day_of_year']\n",
    "future['day_of_month'] = for_future['day_of_month']\n",
    "future['week_of_year'] = for_future['week_of_year']\n",
    "future['lunchbreak_YES'] = for_future['lunchbreak_YES']\n",
    "future['classtime_YES'] = for_future['classtime_YES']\n",
    "future['WEEKEND'] = for_future['WEEKEND']\n",
    "future['holiday_NORMAL'] = for_future['holiday_NORMAL']\n",
    "future['exam_NORMAL'] = for_future['exam_NORMAL']\n",
    "future['temperature'] = for_future['temperature']\n",
    "future['humidity'] = for_future['humidity']\n",
    "future['wind_speed'] = for_future['wind_speed']\n",
    "future['pressure'] = for_future['pressure']\n",
    "# future['2018/2'] = for_future['2018/2']\n",
    "future['2018/SUMMER'] = for_future['2018/SUMMER']\n",
    "future['2019/1'] = for_future['2019/1']\n",
    "future['HOLIDAY'] = for_future['HOLIDAY']\n",
    "# future['Cloudy'] = for_future['Cloudy']\n",
    "future['Fair'] = for_future['Fair']\n",
    "future['Fair / Windy'] = for_future['Fair / Windy']\n",
    "future['Fog'] = for_future['Fog']\n",
    "future['Haze'] = for_future['Haze']\n",
    "future['Heavy Rain'] = for_future['Heavy Rain']\n",
    "future['Heavy Rain / Windy'] = for_future['Heavy Rain / Windy']\n",
    "future['Heavy T-Storm'] = for_future['Heavy T-Storm']\n",
    "future['Heavy T-Storm / Windy'] = for_future['Heavy T-Storm / Windy']\n",
    "future['Light Rain'] = for_future['Light Rain']\n",
    "future['Light Rain Shower'] = for_future['Light Rain Shower']\n",
    "future['Light Rain Shower / Windy'] = for_future['Light Rain Shower / Windy']\n",
    "future['Light Rain with Thunder'] = for_future['Light Rain with Thunder']\n",
    "future['Mostly Cloudy'] = for_future['Mostly Cloudy']\n",
    "future['Mostly Cloudy / Windy'] = for_future['Mostly Cloudy / Windy']\n",
    "future['Partly Cloudy'] = for_future['Partly Cloudy']\n",
    "future['Partly Cloudy / Windy'] = for_future['Partly Cloudy / Windy']\n",
    "future['Rain'] = for_future['Rain']\n",
    "future['Rain / Windy'] = for_future['Rain / Windy']\n",
    "future['Rain Shower'] = for_future['Rain Shower']\n",
    "future['Showers in the Vicinity'] = for_future['Showers in the Vicinity']\n",
    "future['T-Storm'] = for_future['T-Storm']\n",
    "future['T-Storm / Windy'] = for_future['T-Storm / Windy']\n",
    "future['Thunder'] = for_future['Thunder']\n",
    "future['Thunder in the Vicinity'] = for_future['Thunder in the Vicinity']\n",
    "\n",
    "forecast = m.predict(future)\n",
    "yhat_round = []\n",
    "for each in forecast['yhat_upper']:\n",
    "#     if ((each*10)%10 >= 6):\n",
    "#         each = math.ceil(each)\n",
    "#     else:\n",
    "#         each = math.floor(each)\n",
    "        \n",
    "    if(each < 0):\n",
    "        each = 0\n",
    "#     elif ((each*10)%10 >= 8):\n",
    "#         each = math.ceil(each)\n",
    "#     else:\n",
    "#         each = math.floor(each)\n",
    "\n",
    "#     each = math.ceil(each)\n",
    "    yhat_round.append(each)\n",
    "# forecast['yhat'] = yhat_round\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.plot(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_result = forecast[['ds', 'yhat']]\n",
    "forecast_result.reset_index(drop=True, inplace=True)\n",
    "forecast_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(df):\n",
    "    each_date = []\n",
    "    \n",
    "    for ts in df['ds']:\n",
    "        ts = str(ts)\n",
    "        date = ts[0:10]\n",
    "        each_date.append(date)\n",
    "    \n",
    "    df['date'] = each_date\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_fit = forecast_result.iloc[:len(X_train)]\n",
    "forecast_fit = extract_date(forecast_fit)\n",
    "forecast_fit['date'] = pd.to_datetime(forecast_fit['date'], dayfirst=True)\n",
    "forecast_fit = forecast_fit.groupby(['date']).sum()\n",
    "forecast_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "forecast_test = forecast_result.iloc[len(X_train):]\n",
    "forecast_test = extract_date(forecast_test)\n",
    "forecast_test['date'] = pd.to_datetime(forecast_test['date'], dayfirst=True)\n",
    "forecast_test = forecast_test.groupby(['date']).sum()\n",
    "forecast_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "def join_eva(train, forecast):\n",
    "    forecast = forecast[:len(train)]\n",
    "    \n",
    "    return forecast.set_index('ds')[['yhat', 'yhat_lower', 'yhat_upper']].join(train.set_index('ds'))\n",
    "\n",
    "def cal_metrics(df):\n",
    "    print(df)\n",
    "    r2 = r2_score(df['y'], df['yhat'])\n",
    "    rmse = np.sqrt(mean_squared_error(df['y'], df['yhat']))\n",
    "    mae = mean_absolute_error(df['y'], df['yhat'])\n",
    "    \n",
    "    return 'r2:', np.round(r2,4), 'rmse', np.round(rmse, 4), 'mae', np.round(mae, 4)\n",
    "\n",
    "def join_test(test, forecast):\n",
    "    forecast = forecast[-len(test):]\n",
    "    \n",
    "    return forecast.set_index('ds')[['yhat', 'yhat_lower', 'yhat_upper']].join(test.set_index('ds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_result = join_eva(X_train, forecast)\n",
    "print(cal_metrics(train_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_result = join_test(X_test, forecast)\n",
    "print(cal_metrics(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15))\n",
    "plt.subplot(311)\n",
    "plt.plot(train_plot, label='actual (train)', color='g')\n",
    "plt.plot(forecast_fit, label='forecast (train)', color='r')\n",
    "plt.plot(test_plot, label='actual (test)', color='#1f77b4')\n",
    "plt.plot(forecast_test, label='forecast (test)', color='#ff7f0e')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.xlabel('Month (Aggregrated Daily)', fontsize=20, labelpad=20)\n",
    "plt.ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.subplot(312)\n",
    "plt.plot(test_plot, label='actual (test)')\n",
    "plt.plot(forecast_test, label='forecast (test)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.xlabel('Month (Test Set Only)', fontsize=20, labelpad=20)\n",
    "plt.ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.subplot(313)\n",
    "for_plot = test_result[-27:]\n",
    "plt.plot(for_plot['y'], label='actual (hourly)')\n",
    "plt.plot(for_plot['yhat'], label='forecast (hourly)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.xlabel('Hour (2 Days)', fontsize=20, labelpad=20)\n",
    "plt.ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_plot, forecast_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_summed(y, yhat):\n",
    "#     print(df)\n",
    "    r2 = r2_score(y, yhat)\n",
    "    rmse = np.sqrt(mean_squared_error(y, yhat))\n",
    "    mae = mean_absolute_error(y, yhat)\n",
    "    \n",
    "    return 'r2:', np.round(r2,4), 'rmse', np.round(rmse, 4), 'mae', np.round(mae, 4)\n",
    "\n",
    "print(cal_summed(test_plot, forecast_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test\n",
    "all features no round (0.2503, 0.5668, 0.3592)\n",
    "\n",
    "pure no round (0.1806, 0.5925, 0.4352)\n",
    "pure round at 5 (0.0887, 0.6249, 0.2762)\n",
    "pure round at 6 (0.0998, 0.6211, 0.2619)\n",
    "\n",
    "\n",
    "all features round at 5 (0.1665, 0.5976, 0.2714)\n",
    "all features round at 6 (0.1665, 0.5976, 0.2429)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "result=[]\n",
    "size=[]\n",
    "i=0\n",
    "tscv = TimeSeriesSplit()\n",
    "for tr_index, val_index in tscv.split(X_train):\n",
    "    print(\"TRAIN:\", tr_index, \"TEST:\", val_index)\n",
    "    X_tr, X_val = X_train.iloc[tr_index], X_train.iloc[val_index]\n",
    "#     y_tr, y_val = y_train.iloc[tr_index], y_train.iloc[val_index]\n",
    "    \n",
    "    X_tr['cap'] = 4\n",
    "    X_tr['floor'] = 0\n",
    "    m = Prophet(growth='logistic', changepoint_prior_scale=0.1)\n",
    "    m = Prophet(changepoint_prior_scale=0.05)\n",
    "#     m.add_regressor('date_of_week')\n",
    "#     m.add_regressor('hour')\n",
    "#     m.add_regressor('quarter_of_year')\n",
    "#     m.add_regressor('month')\n",
    "#     m.add_regressor('day_of_year')\n",
    "#     m.add_regressor('day_of_month')\n",
    "#     m.add_regressor('week_of_year')\n",
    "#     m.add_regressor('is_lunch_break')\n",
    "#     m.add_regressor('is_class_time')\n",
    "#     m.add_regressor('temperature_normalized')\n",
    "#     m.add_regressor('humidity_normalized')\n",
    "#     m.add_regressor('wind_speed_normalized')\n",
    "#     m.add_regressor('pressure_normalized')\n",
    "#     m.add_regressor('2018/SUMMER')\n",
    "#     m.add_regressor('2019/1')\n",
    "#     m.add_regressor('HOLIDAY')\n",
    "#     m.add_regressor('Fair')\n",
    "#     m.add_regressor('Fair / Windy')\n",
    "#     m.add_regressor('Fog')\n",
    "#     m.add_regressor('Haze')\n",
    "#     m.add_regressor('Heavy Rain')\n",
    "#     m.add_regressor('Heavy Rain / Windy')\n",
    "#     m.add_regressor('Heavy T-Storm')\n",
    "#     m.add_regressor('Heavy T-Storm / Windy')\n",
    "#     m.add_regressor('Light Rain')\n",
    "#     m.add_regressor('Light Rain Shower')\n",
    "#     m.add_regressor('Light Rain Shower / Windy')\n",
    "#     m.add_regressor('Light Rain with Thunder')\n",
    "#     m.add_regressor('Mostly Cloudy')\n",
    "#     m.add_regressor('Mostly Cloudy / Windy')\n",
    "#     m.add_regressor('Partly Cloudy')\n",
    "#     m.add_regressor('Partly Cloudy / Windy')\n",
    "#     m.add_regressor('Rain')\n",
    "#     m.add_regressor('Rain / Windy')\n",
    "#     m.add_regressor('Rain Shower')\n",
    "#     m.add_regressor('Showers in the Vicinity')\n",
    "#     m.add_regressor('T-Storm')\n",
    "#     m.add_regressor('T-Storm / Windy')\n",
    "#     m.add_regressor('Thunder')\n",
    "#     m.add_regressor('Thunder in the Vicinity')\n",
    "    m.fit(X_tr)\n",
    "    \n",
    "    future = m.make_future_dataframe(periods=size[i], freq='H')\n",
    "    i += 1\n",
    "    future['cap'] = 4\n",
    "    future['floor'] = 0\n",
    "    future = future[(future['ds'].dt.hour >= 7) & (future['ds'].dt.hour < 21)]\n",
    "#     future = future[future['ds'].dt.dayofweek < 5]\n",
    "    future.reset_index(drop=True, inplace=True)\n",
    "#     future['date_of_week'] = X_val['date_of_week']\n",
    "#     future['hour'] = X_val['hour']\n",
    "#     future['quarter_of_year'] = X_val['quarter_of_year']\n",
    "#     future['month'] = X_val['month']\n",
    "#     future['day_of_year'] = X_val['day_of_year']\n",
    "#     future['day_of_month'] = X_val['day_of_month']\n",
    "#     future['week_of_year'] = X_val['week_of_year']\n",
    "#     future['is_lunch_break'] = X_val['is_lunch_break']\n",
    "#     future['is_class_time'] = X_val['is_class_time']\n",
    "#     future['temperature_normalized'] = X_val['temperature_normalized']\n",
    "#     future['humidity_normalized'] = X_val['humidity_normalized']\n",
    "#     future['wind_speed_normalized'] = X_val['wind_speed_normalized']\n",
    "#     future['pressure_normalized'] = X_val['pressure_normalized']\n",
    "#     future['2018/SUMMER'] = X_val['2018/SUMMER']\n",
    "#     future['2019/1'] = X_val['2019/1']\n",
    "#     future['HOLIDAY'] = X_val['HOLIDAY']\n",
    "#     future['Fair'] = X_val['Fair']\n",
    "#     future['Fair / Windy'] = X_val['Fair / Windy']\n",
    "#     future['Fog'] = X_val['Fog']\n",
    "#     future['Haze'] = X_val['Haze']\n",
    "#     future['Heavy Rain'] = X_val['Heavy Rain']\n",
    "#     future['Heavy Rain / Windy'] = X_val['Heavy Rain / Windy']\n",
    "#     future['Heavy T-Storm'] = X_val['Heavy T-Storm']\n",
    "#     future['Heavy T-Storm / Windy'] = X_val['Heavy T-Storm / Windy']\n",
    "#     future['Light Rain'] = X_val['Light Rain']\n",
    "#     future['Light Rain Shower'] = X_val['Light Rain Shower']\n",
    "#     future['Light Rain Shower / Windy'] = X_val['Light Rain Shower / Windy']\n",
    "#     future['Light Rain with Thunder'] = X_val['Light Rain with Thunder']\n",
    "#     future['Mostly Cloudy'] = X_val['Mostly Cloudy']\n",
    "#     future['Mostly Cloudy / Windy'] = X_val['Mostly Cloudy / Windy']\n",
    "#     future['Partly Cloudy'] = X_val['Partly Cloudy']\n",
    "#     future['Partly Cloudy / Windy'] = X_val['Partly Cloudy / Windy']\n",
    "#     future['Rain'] = X_val['Rain']\n",
    "#     future['Rain / Windy'] = X_val['Rain / Windy']\n",
    "#     future['Rain Shower'] = X_val['Rain Shower']\n",
    "#     future['Showers in the Vicinity'] = X_val['Showers in the Vicinity']\n",
    "#     future['T-Storm'] = X_val['T-Storm']\n",
    "#     future['T-Storm / Windy'] = X_val['T-Storm / Windy']\n",
    "#     future['Thunder'] = X_val['Thunder']\n",
    "#     future['Thunder in the Vicinity'] = X_val['Thunder in the Vicinity']\n",
    "\n",
    "    forecast = m.predict(future)\n",
    "    yhat_round = []\n",
    "    for each in forecast['yhat']:\n",
    "        if ((each*10)%10 >= 6):\n",
    "            each = math.ceil(each)\n",
    "        else:\n",
    "            each = math.floor(each)\n",
    "    #     each = math.ceil(each)\n",
    "        yhat_round.append(each)\n",
    "    forecast['yhat'] = yhat_round\n",
    "    forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
    "    \n",
    "    m.plot(forecast)\n",
    "    train_result = join_eva(X_tr, forecast)\n",
    "    result.append(cal_metrics(train_result))\n",
    "    test_result = join_test(X_val, forecast)\n",
    "    result.append(cal_metrics(test_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import product\n",
    "import statsmodels as sm\n",
    "import statsmodels.api as sm_api\n",
    "import statsmodels.tsa.api as smt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf,pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from pylab import rcParams\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endo = X_train_clone[['ds', 'y']]\n",
    "endo['ds'] = pd.to_datetime(endo['ds'], dayfirst=True)\n",
    "endo.set_index('ds', inplace=True)\n",
    "endo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo = X_train_clone.drop(['y', 'count_0412', 'count_1211'],axis=1)\n",
    "exo['ds'] = pd.to_datetime(exo['ds'], dayfirst=True)\n",
    "exo.set_index('ds', inplace=True)\n",
    "exo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exo_test = X_test_clone.drop(['y', 'count_0412', 'count_1211'],axis=1)\n",
    "exo_test['ds'] = pd.to_datetime(exo_test['ds'], dayfirst=True)\n",
    "exo_test.set_index('ds', inplace=True)\n",
    "exo_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plot(y, lags=None, figsize=(14,7), style='bmh'):\n",
    "#     if not isinstance(y, pd.Series):\n",
    "#         y = pd.Series(y)\n",
    "    with plt.style.context(style='bmh'):\n",
    "        fig = plt.figure(figsize=figsize)\n",
    "        layout = (2,2)\n",
    "        ts_ax = plt.subplot2grid(layout, (0,0), colspan=2)\n",
    "        acf_ax = plt.subplot2grid(layout, (1,0))\n",
    "        pacf_ax = plt.subplot2grid(layout, (1,1))\n",
    "        y.plot(ax=ts_ax)\n",
    "        p_value = sm.tsa.stattools.adfuller(y)[1]\n",
    "        ts_ax.set_title('TSA-DF: p={0:5f}'.format(p_value))\n",
    "        smt.graphics.plot_acf(y, lags=lags, ax=acf_ax)\n",
    "        smt.graphics.plot_pacf(y, lags=lags, ax=pacf_ax)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "ts_plot(endo, lags=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 18, 8\n",
    "decomposition = seasonal_decompose(endo, freq=14, model='additive')\n",
    "fig = decomposition.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = range(0, 2)\n",
    "d = 0\n",
    "q = range(0, 3)\n",
    "s = 14\n",
    "pdq = []\n",
    "seasonal_pdq = []\n",
    "for ar in p:\n",
    "    for ma in q:\n",
    "        param = (ar, d, ma)\n",
    "        sparam = (ar, d, ma, s)\n",
    "        pdq.append(param)\n",
    "        seasonal_pdq.append(sparam)\n",
    "\n",
    "print('Examples of parameter combinations for Seasonal ARIMA...')\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[1]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[1], seasonal_pdq[2]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[3]))\n",
    "print('SARIMAX: {} x {}'.format(pdq[2], seasonal_pdq[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in pdq:\n",
    "    for param_seasonal in seasonal_pdq:\n",
    "        try:\n",
    "            mod = sm_api.tsa.statespace.SARIMAX(endo, exog=exo, order=param, seasonal_order=param_seasonal, enforce_stationarity=False, enforce_invertibility=False)\n",
    "            results = mod.fit()\n",
    "            print('SARIMAX{}x{}14 - AIC:{}'.format(param, param_seasonal, results.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = sm_api.tsa.statespace.SARIMAX(endog=endo, exog=exo,\n",
    "                                order=(0, 0, 2),\n",
    "                                seasonal_order=(2, 0, 2, 14),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "print(results.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot_diagnostics(figsize=(16, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = results.get_prediction(start=pd.to_datetime('2019-02-01 07:00:00'), dynamic=False)\n",
    "pred_ci = pred.conf_int()\n",
    "\n",
    "ax = endo[pd.to_datetime('2019-01-07 07:00:00'):].plot(label='observed', figsize=(25, 15))\n",
    "pred.predicted_mean.plot(ax=ax, label='One-step ahead Forecast', alpha=.7)\n",
    "ax.fill_between(pred_ci.index,\n",
    "                pred_ci.iloc[:, 0],\n",
    "                pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
    "ax.set_xlabel('Hour', fontsize=20, labelpad=20)\n",
    "ax.set_ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_uc = results.get_forecast(steps=420, exog=exo_test)\n",
    "pred_ci = pred_uc.conf_int()\n",
    "\n",
    "plt.plot(pred_uc.predicted_mean)\n",
    "print(pred_uc.predicted_mean, pred_ci.iloc[:, 1])\n",
    "# ax = train_arima.plot(label='observed', figsize=(20, 15))\n",
    "# pred_uc.predicted_mean.plot(ax=ax, label='Forecast')\n",
    "# ax.fill_between(pred_ci.index,\n",
    "#                 pred_ci.iloc[:, 0],\n",
    "#                 pred_ci.iloc[:, 1], color='k', alpha=.25)\n",
    "# ax.set_xlabel('Date')\n",
    "# ax.set_ylabel('Demand Hourly')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = pred_uc.predicted_mean\n",
    "yhat.reset_index(drop=True, inplace=True)\n",
    "X_test_clone['yhat'] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cal_metrics(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_sarimax = X_test_clone[['ds', 'y']]\n",
    "this = pred_uc.predicted_mean.reset_index(drop=True)\n",
    "for_sarimax['yhat'] = this\n",
    "for_sarimax = extract_date(for_sarimax)\n",
    "for_sarimax['date'] = pd.to_datetime(for_sarimax['date'], dayfirst=True)\n",
    "\n",
    "y_actual = for_sarimax[['date', 'y']]\n",
    "y_actual.set_index('date', inplace=True)\n",
    "y_actual = y_actual.groupby(['date']).sum()\n",
    "yhat = for_sarimax[['date', 'yhat']]\n",
    "yhat.set_index('date', inplace=True)\n",
    "yhat = yhat.groupby(['date']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15))\n",
    "plt.plot(y_actual, label='actual (test)')\n",
    "plt.plot(yhat, label='forecast (test)')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=20)\n",
    "plt.xlabel('Month (Test Set Only)', fontsize=20, labelpad=20)\n",
    "plt.ylabel('Demand', fontsize=20, labelpad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['count_1204']\n",
    "X = df.drop(['date', 'time', 'timestamp', 'count_1204', 'count_0412', 'count_1211'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "y_train_rfr = X_train[['y']]\n",
    "X_train_rfr = X_train.drop(['ds', 'y'], axis=1)\n",
    "y_test_rfr = X_test[['y']]\n",
    "X_test_rfr = X_test.drop(['ds', 'y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', X_train_rfr.shape)\n",
    "print('Training Labels Shape:', y_train_rfr.shape)\n",
    "print('Testing Features Shape:', X_test_rfr.shape)\n",
    "print('Testing Labels Shape:', y_test_rfr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_na = X_train[['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "X_train.drop(['temperature', 'humidity', 'wind_speed', 'pressure'], axis=1, inplace=True)\n",
    "\n",
    "X_test_na = X_test[['temperature', 'humidity', 'wind_speed', 'pressure']]\n",
    "X_test.drop(['temperature', 'humidity', 'wind_speed', 'pressure'], axis=1, inplace=True)\n",
    "\n",
    "X_train_na.fillna(X_train_na.mean(), inplace=True)\n",
    "X_test_na.fillna(X_test_na.mean(), inplace=True)\n",
    "\n",
    "# scaler = StandardScaler().fit(X_train_na)\n",
    "scaler = MinMaxScaler().fit(X_train_na)\n",
    "X_train_na = pd.DataFrame(scaler.fit_transform(X_train_na), columns=X_train_na.columns)\n",
    "X_test_na = pd.DataFrame(scaler.fit_transform(X_test_na), columns=X_test_na.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_na = pd.DataFrame(scaler.fit_transform(X_train_na), columns=X_train_na.columns)\n",
    "X_test_na = pd.DataFrame(scaler.fit_transform(X_test_na), columns=X_test_na.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_train_na.reset_index(drop=True, inplace=True)\n",
    "X_test.reset_index(drop=True, inplace=True)\n",
    "X_test_na.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_train_na], axis=1)\n",
    "X_test = pd.concat([X_test, X_test_na], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators = 150, random_state = 0,\n",
    "                                   min_samples_split=8, min_samples_leaf=10,max_depth=100)\n",
    "# model = RandomForestRegressor(n_estimators= 1000,\n",
    "#  min_samples_split= 2,\n",
    "#  min_samples_leaf= 4)\n",
    "model.fit(X_train_rfr, y_train_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_test_rfr)\n",
    "r2 = r2_score(y_test_rfr, y_predicted)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_rfr, y_predicted))\n",
    "mae = mean_absolute_error(y_test_rfr, y_predicted)\n",
    "\n",
    "print('R2: ', np.round(r2, 4))\n",
    "print('RMSE: ', np.round(rmse, 4))\n",
    "print('MAE: ', np.round(mae, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all features v3\n",
    "R2:  0.8892\n",
    "RMSE:  0.1385\n",
    "MAE:  0.0636\n",
    "\n",
    "all features v4\n",
    "\n",
    "{'n_estimators': 200,\n",
    " 'min_samples_split': 5,\n",
    " 'min_samples_leaf': 4,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 80,\n",
    " 'bootstrap': True}\n",
    "\n",
    "R2:  0.3049\n",
    "RMSE:  0.3727\n",
    "MAE:  0.1842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fi = pd.Series(model.feature_importances_, index=X_train_rfr.columns).sort_values(ascending=False)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = model.estimators_[5]\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = X.columns, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfr_model(X, y):\n",
    "# Perform Grid-Search\n",
    "    gsc = GridSearchCV(\n",
    "        estimator=RandomForestRegressor(),\n",
    "        param_grid={\n",
    "            'max_depth': range(3,15),\n",
    "            'n_estimators': (10, 50, 100, 1000),},\n",
    "        cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=2)\n",
    "    \n",
    "    grid_result = gsc.fit(X, y)\n",
    "    best_params = grid_result.best_params_\n",
    "    \n",
    "    rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"], random_state=False, verbose=False)\n",
    "# Perform K-Fold CV\n",
    "    scores = cross_val_score(rfr, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 100, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 4, 6, 8, 10]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = True\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = 3)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train_rfr, y_train_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    y_predicted = model.predict(test_features)\n",
    "    r2 = r2_score(y_test_rfr, y_predicted)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_rfr, y_predicted))\n",
    "    mae = mean_absolute_error(y_test_rfr, y_predicted)\n",
    "    print('R2: ', np.round(r2, 4))\n",
    "    print('RMSE: ', np.round(rmse, 4))\n",
    "    print('MAE: ', np.round(mae, 4))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test_rfr, y_test_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 80, random_state = 42, \n",
    "                                   min_samples_split=8, min_samples_leaf=6,max_depth= 80)\n",
    "base_model.fit(X_train_rfr, y_train_rfr)\n",
    "base_accuracy = evaluate(base_model, X_test_rfr, y_test_rfr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 5, verbose=2, n_jobs = 3)\n",
    "CV_rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'max_depth': 80,\n",
    " 'min_samples_leaf': 6,\n",
    " 'min_samples_split': 8,\n",
    " 'n_estimators': 100}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
